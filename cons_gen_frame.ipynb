{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LIBRARIES #####\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import *\n",
    "from gurobipy import GRB\n",
    "import gurobipy as gp\n",
    "from itertools import product\n",
    "import time\n",
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import math\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from statistics import mean\n",
    "import threading\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from mnist import MNIST # import mnist parser\n",
    "import itertools\n",
    "import time\n",
    "import logging\n",
    "from sklearn.model_selection import KFold # for k folding\n",
    "from sklearn.model_selection import RepeatedKFold # for k folding\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config pc\n",
    "global pc_name\n",
    "global log_folder\n",
    "global pushover_token\n",
    "global output_folder\n",
    "\n",
    "if os.environ['COMPUTERNAME'] == \"KTMELDCGLXJQ3\":\n",
    "    log_folder = 'logs/elderax/'\n",
    "    output_folder = 'outputs/elderax/'\n",
    "    pc_name = 'Elderax'\n",
    "    pushover_token = \"aqmbyd1nsw7ir86sdx1mchq9o68vpg\"\n",
    "    \n",
    "elif os.environ['COMPUTERNAME'] == \"TSMELDPC0YSGRF\":\n",
    "    log_folder = 'logs/griffon/'\n",
    "    output_folder = 'outputs/griffon/'\n",
    "    pc_name = 'Griffon'\n",
    "    pushover_token = \"aqmbyd1nsw7ir86sdx1mchq9o68vpg\"\n",
    "\n",
    "elif os.environ['COMPUTERNAME'] == \"KTMELLB8HRYZ2\":\n",
    "    log_folder = 'logs/henry/'\n",
    "    output_folder = 'outputs/henry/'\n",
    "    pc_name = 'Henry'\n",
    "    pushover_token = \"axa4j4ryxzj5uvt53hv67scaunihs9\"\n",
    "\n",
    "elif os.environ['COMPUTERNAME'] == \"QUEEN-DESKTOP\":\n",
    "    log_folder = 'logs/queen/'\n",
    "    output_folder = 'outputs/queen/'\n",
    "    pc_name = 'Queen'\n",
    "    pushover_token = \"axa4j4ryxzj5uvt53hv67scaunihs9\"\n",
    "    \n",
    "else:\n",
    "    log_folder = 'logs/unknown/'\n",
    "    pc_name = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record_folder(dataset, ibudget, start_time_main):\n",
    "    folder_path = f\"records/{pc_name}/{start_time_main.strftime('%Y-%m-%d_%H-%M-%S')}_dataset-{dataset}_ibudget-{ibudget}/\" # folder name\n",
    "    try:\n",
    "        os.mkdir(folder_path) # create folder\n",
    "        return folder_path # return folder name\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        return folder_path # return folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_save(saving_dict, file_name, ext, folder=output_folder):\n",
    "    \n",
    "    i = 10000\n",
    "    while os.path.exists(f\"{folder}{file_name}-{i}.{ext}\"):\n",
    "        i += 1\n",
    "\n",
    "    with open(f\"{folder}{file_name}-{i}.{ext}\", 'wb') as f:\n",
    "        pickle.dump(saving_dict, f)\n",
    "        \n",
    "def dict_load(file_name, pc_name=pc_name):\n",
    "\n",
    "    with open('outputs/' + pc_name.lower() + '/' + file_name, 'rb') as f:\n",
    "        loading_dict = pickle.load(f)\n",
    "    return dict(loading_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config loguru\n",
    "from loguru import logger\n",
    "    \n",
    "logger.remove() # clear existing loggers/sinks\n",
    "\n",
    "# adv example\n",
    "def log_adv_example_gen(msg):\n",
    "    logger_adv = logger.bind(task=\"adv_example_gen\")\n",
    "    logger_adv.info(msg)\n",
    "\n",
    "def clear_log_adv_example_gen():\n",
    "    open(log_folder + \"adv_example_gen.log\", 'w').close()\n",
    "\n",
    "logger.add(log_folder + \"adv_example_gen.log\",\n",
    "           format=\"{time:HH:mm:ss.SS} | {level} | {message}\",\n",
    "           filter=lambda record: record[\"extra\"][\"task\"] == \"adv_example_gen\",)\n",
    "\n",
    "# adv train\n",
    "def log_adv_train(msg):\n",
    "    logger_adv_train = logger.bind(task=\"adv_train\")\n",
    "    logger_adv_train.info(msg)\n",
    "\n",
    "def clear_log_adv_train():\n",
    "    open(log_folder + \"adv_train.log\", 'w').close()\n",
    "\n",
    "logger.add(log_folder + \"adv_train.log\",\n",
    "           format=\"{time:HH:mm:ss.SS} | {level} | {message}\",\n",
    "           filter=lambda record: record[\"extra\"][\"task\"] == \"adv_train\",)\n",
    "\n",
    "# optimize model\n",
    "def log_model_optimize(msg):\n",
    "    logger_model_optimize = logger.bind(task=\"model_optimize\")\n",
    "    logger_model_optimize.info(msg)\n",
    "\n",
    "def clear_log_model_optimize():\n",
    "    open(log_folder + \"model_optimize.log\", 'w').close()\n",
    "\n",
    "logger.add(log_folder + \"model_optimize.log\",\n",
    "           format=\"{time:HH:mm:ss.SS} | {level} | {message}\",\n",
    "           filter=lambda record: record[\"extra\"][\"task\"] == \"model_optimize\",)\n",
    "\n",
    "# cut vs2\n",
    "def log_adv_cut_v2(msg):\n",
    "    logger_model_optimize = logger.bind(task=\"adv_cut_v2\")\n",
    "    logger_model_optimize.info(msg)\n",
    "\n",
    "def clear_log_adv_cut_v2():\n",
    "    open(log_folder + \"adv_cut_v2.log\", 'w').close()\n",
    "\n",
    "logger.add(log_folder + \"adv_cut_v2.log\",\n",
    "           format=\"{time:HH:mm:ss.SS} | {level} | {message}\",\n",
    "           filter=lambda record: record[\"extra\"][\"task\"] == \"adv_cut_v2\",)\n",
    "\n",
    "# main\n",
    "def log_main(msg):\n",
    "    logger_main = logger.bind(task=\"main\")\n",
    "    logger_main.info(msg)\n",
    "\n",
    "def clear_log_main():\n",
    "    open(log_folder + \"main.log\", 'w').close()\n",
    "\n",
    "logger.add(log_folder + \"main.log\",\n",
    "           format=\"{time:HH:mm:ss.SS} | {level} | {message}\",\n",
    "           filter=lambda record: record[\"extra\"][\"task\"] == \"main\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config onedrive\n",
    "def onedrive(action='start', active=0):\n",
    "    # stop your onedrive (else will keep syncing logs)   \n",
    "    \n",
    "    # on by default on Griffon and Henry\n",
    "    if pc_name == 'Griffon' or pc_name == 'Henry' or pc_name == 'Queen' or active == 1:\n",
    "\n",
    "        if action == 'start':    \n",
    "            if pc_name == \"Elderax\":\n",
    "                !start \"OneDrive\" /B \"%LOCALAPPDATA%\\Microsoft\\OneDrive\\onedrive\" /background\n",
    "                return None\n",
    "            if pc_name == \"Griffon\":\n",
    "                !start \"OneDrive\" /B \"C:\\Program Files\\Microsoft OneDrive\\onedrive\" /background\n",
    "                return None\n",
    "            if pc_name == \"Henry\":\n",
    "                !start \"OneDrive\" /B \"%LOCALAPPDATA%\\Microsoft\\OneDrive\\onedrive\" /background\n",
    "                return None\n",
    "            if pc_name == \"Queen\":\n",
    "                !start \"OneDrive\" /B \"C:\\Program Files\\Microsoft OneDrive\\onedrive\" /background\n",
    "                return None\n",
    "        \n",
    "        if action == 'stop':\n",
    "            if pc_name == \"Elderax\":\n",
    "                !\"%LOCALAPPDATA%\\Microsoft\\OneDrive\\onedrive\" /shutdown\n",
    "                return None\n",
    "            if pc_name == \"Griffon\":\n",
    "                !\"C:\\Program Files\\Microsoft OneDrive\\onedrive\" /shutdown\n",
    "                return None\n",
    "            if pc_name == \"Henry\":\n",
    "                !\"%LOCALAPPDATA%\\Microsoft\\OneDrive\\onedrive\" /shutdown\n",
    "                return None\n",
    "            if pc_name == \"Queen\":\n",
    "                !\"C:\\Program Files\\Microsoft OneDrive\\onedrive\" /shutdown\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pushover config\n",
    "import http.client, urllib\n",
    "def pushover(title=\"Model\", msg=\"Test\", active=0, device=\"Elderax_Edge,Elderax_Chrome,Y8\"):\n",
    "    \n",
    "    # on by default on Griffon and Henry\n",
    "    if pc_name == 'Griffon' or pc_name == 'Henry' or pc_name == 'Queen' or active == 1:\n",
    "        \n",
    "        conn = http.client.HTTPSConnection(\"api.pushover.net:443\")\n",
    "        conn.request(\"POST\", \"/1/messages.json\",\n",
    "        urllib.parse.urlencode({\n",
    "            \"token\": pushover_token,\n",
    "            \"user\": \"BAguidPakA2RfKFaNhqQfCsrbExyce\",\n",
    "            \"message\": msg,\n",
    "            \"title\": title,\n",
    "            \"device\": pc_name,\n",
    "        }), { \"Content-type\": \"application/x-www-form-urlencoded\" })\n",
    "        conn.getresponse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DATA #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_binazrize(row, col_means):\n",
    "    \"\"\" binarise, 0 if <= avg, 1 if > avg \"\"\"\n",
    "    \n",
    "    for c1 in row.index: # for each col in row\n",
    "        for c2 in col_means.index: # for each col in means\n",
    "            if c1==c2: # if col names match do a comparison\n",
    "                if row[c1] > col_means[c1]: # if row value greater then mean 1\n",
    "                    row[c1] = 1\n",
    "                else:\n",
    "                    row[c1] = 0\n",
    "        # print(r)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load_mnist(f=0, n=0):\n",
    "    # mndata = MNIST('.data/mnist/')\n",
    "    mn_path = os.path.join( os.getcwd(), 'data\\\\mnist\\\\') # combining with working directory\n",
    "    mndata = MNIST(mn_path)\n",
    "    images, labels = mndata.load_training()\n",
    "        \n",
    "    dfx = pd.DataFrame(images)\n",
    "    dfy = pd.DataFrame(labels)\n",
    "    dfy = pd.get_dummies(dfy[0]) # one hot encode\n",
    "\n",
    "    # reduce to f features if f != 0 (for loading less data)\n",
    "    if f > 0:\n",
    "        dfx = dfx.loc[:, :f]\n",
    "        dfy = dfy.loc[:, :f]\n",
    "    # reduce to n samples if n != 0 (for loading less data)\n",
    "    if n > 0:\n",
    "        dfx = dfx.loc[:n, :]\n",
    "        dfy = dfy.loc[:n, :]\n",
    "    \n",
    "    # shuffle datasets in sync\n",
    "    idx = np.random.permutation(dfy.index)\n",
    "    dfx = dfx.reindex(idx).reset_index(drop=True)\n",
    "    dfy = dfy.reindex(idx).reset_index(drop=True)\n",
    "    \n",
    "    # split test and training set\n",
    "    dfx_train, dfx_test, dfy_train, dfy_test = train_test_split(dfx, dfy, test_size=0.3, random_state=11)\n",
    "    \n",
    "    # reset indexes\n",
    "    dfx_train = dfx_train.reset_index(drop=True)\n",
    "    dfx_test = dfx_test.reset_index(drop=True)\n",
    "    dfy_train = dfy_train.reset_index(drop=True)\n",
    "    dfy_test = dfy_test.reset_index(drop=True) \n",
    "    \n",
    "    # print(f'dfx_train: {dfx_train.shape} | dfy_train: {dfy_train.shape} || dfx_test: {dfx_test.shape} | dfy_test:{dfy_test}')\n",
    "\n",
    "    return dfx_train, dfx_test, dfy_train, dfy_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(file_path, header, col_y_idx0, dfx_col_idx0_drop_ls, \n",
    "                 bin_cols_dict, delimiter, print_out, test_size=0.3, k=0, n=0, seed_val=123):\n",
    "    \"\"\" prepare data for use by load_data() \"\"\"\n",
    "    \n",
    "    # file_path = './data/zoo/zoo.data'\n",
    "    # header = None # None or 0 (first row)\n",
    "    # col_y_idx0 = 17 # col num (ind 0) that has predicted class from df\n",
    "    # dfx_col_idx0_drop_ls = [col_y_idx0, 0] # y column and any other idx if need be (0 here)\n",
    "    # bin_cols_dict = {} # colname, bins\n",
    "\n",
    "    # load data\n",
    "    df = pd.read_csv(file_path, header=header, delimiter=delimiter)\n",
    "\n",
    "    ######################## DF #########################\n",
    "    # print(df)\n",
    "\n",
    "    # shuffle data\n",
    "    \n",
    "    np.random.seed(seed_val) # goes down by 1\n",
    "    \n",
    "    # np.random.seed(1) # goes down by 1\n",
    "    # np.random.seed(12) # same\n",
    "    # np.random.seed(123) # 1 and solved = robust\n",
    "    # np.random.seed(1234) # same\n",
    "    # np.random.seed(12345) # up 1 data point\n",
    "    # np.random.seed(123456) # 3 down to robustness\n",
    "    # np.random.seed(1234567) # reduce 1 example\n",
    "    # np.random.seed(12345678) # 1 becomes robust\n",
    "    # df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # limit to n if given (0 mean all datapoints)\n",
    "    if n != 0:\n",
    "        df = df.sample(n=n).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    ######################## DFY #########################\n",
    "\n",
    "    # get predicted class\n",
    "    dfy = pd.DataFrame(df.iloc[: , col_y_idx0]) # get the y labels\n",
    "    dfy.columns = range(dfy.columns.size) # reset column name\n",
    "\n",
    "    # factorise y (no harm in it)\n",
    "    dfy = dfy.apply(lambda x: pd.factorize(x, sort=True)[0]) # factorise all columns in dfy\n",
    "\n",
    "    # one hot encode\n",
    "    dfy = OneHotEncoder().fit_transform(dfy).toarray()\n",
    "    dfy = pd.DataFrame(dfy).astype(int)\n",
    "\n",
    "    ######################## DFX #########################\n",
    "\n",
    "    # prepare\n",
    "    dfx = df.drop(df.columns[dfx_col_idx0_drop_ls], axis=1) # drop columns\n",
    "    dfx.columns = range(dfx.columns.size) # reset column name\n",
    "\n",
    "    # code continous variables (make sure to check idx after dropping cols)\n",
    "    if len(bin_cols_dict) > 0:\n",
    "        for colname, bins in bin_cols_dict.items():\n",
    "            array_temp1 = pd.cut(df[colname], bins) # split to 5\n",
    "            dfx[colname] = pd.factorize(array_temp1, sort=True)[0]\n",
    "            # print(dfx[colname])\n",
    "\n",
    "    # get no. of responses per feature\n",
    "    x_uniq_dict = {}\n",
    "    for colname in dfx:\n",
    "        x_uniq_dict[colname] = dfx[colname].nunique()\n",
    "\n",
    "    dfx_out = pd.DataFrame() # build output dataframe\n",
    "\n",
    "    # factorise (just incase + resets any other encoding)\n",
    "    for colname, uniq in x_uniq_dict.items():\n",
    "        \n",
    "        if uniq <= 2: # for those with 2 classes (or all 1/0)\n",
    "            array_temp2 = pd.factorize(dfx[colname], sort=True)[0] # factorise in case and add to dfx_out\n",
    "        elif uniq > 2: # if more then 2 classes\n",
    "            array_temp2 = OneHotEncoder().fit_transform(dfx[[colname]]).toarray()\n",
    "        \n",
    "        dfx_temp = pd.DataFrame(array_temp2).astype(int) # convert to df and make int\n",
    "            \n",
    "        new_df = len([x for x in dfx_out]) == 0 # if dfx_out is blank ie no columns\n",
    "        if new_df:\n",
    "            dfx_out = dfx_temp\n",
    "            if print_out >= 2:\n",
    "                print(f\"col: {colname} --> onehot --> {uniq} cols\")\n",
    "        else:\n",
    "            dfx_out = dfx_out.join(dfx_temp, rsuffix=\"_o\") # merge into out df\n",
    "            dfx_out.columns = range(dfx_out.columns.size) # reset column names\n",
    "            if print_out >= 2:\n",
    "                print(f\"col: {colname} --> onehot --> {uniq} cols\")\n",
    "\n",
    "    dfx = dfx_out # set dfx to dfx_out (for consistancy)\n",
    "    \n",
    "    # split test and training (test/train or k-fold)\n",
    "    \n",
    "    # k val\n",
    "    if k == 0:\n",
    "        returned_dfs = train_test_split(dfx, dfy, test_size=test_size, random_state=123456)\n",
    "        (dfx_train, dfx_test, dfy_train, dfy_test) = returned_dfs\n",
    "        # print(df) # checking\n",
    "        # print(dfy) # checking\n",
    "        # print(dfx) # checking\n",
    "\n",
    "        # reset indexes\n",
    "        dfx_train = dfx_train.reset_index(drop=True)\n",
    "        dfx_test = dfx_test.reset_index(drop=True)\n",
    "        dfy_train = dfy_train.reset_index(drop=True)\n",
    "        dfy_test = dfy_test.reset_index(drop=True)\n",
    "    \n",
    "        if print_out == 1:\n",
    "            print(f'train/test split w/test_size: {test_size}')\n",
    "            print(f'y_classes: {dfy_train.shape[1]} | x_features: {dfx_train.shape[1]} | n-train: {dfx_train.shape[0]} | n-test: {dfx_test.shape[0]}')\n",
    "         \n",
    "    else:\n",
    "        rkf = RepeatedKFold(n_splits=k, n_repeats=1, random_state=123456)\n",
    "        # rkf = KFold(n_splits=4, random_state=None)\n",
    "\n",
    "        dfx_train_ls = []\n",
    "        dfx_test_ls = []\n",
    "        \n",
    "        dfy_train_ls = []\n",
    "        dfy_test_ls = []\n",
    " \n",
    "        for train_index, test_index in rkf.split(dfx):\n",
    "            # print(train_index, test_index)\n",
    "            x_train = dfx.loc[train_index].reset_index(drop=True)\n",
    "            x_test = dfx.loc[test_index].reset_index(drop=True)\n",
    "            dfx_train_ls.append(x_train)\n",
    "            dfx_test_ls.append(x_test)\n",
    "            \n",
    "            y_train = dfy.loc[train_index].reset_index(drop=True)\n",
    "            y_test = dfy.loc[test_index].reset_index(drop=True)\n",
    "            dfy_train_ls.append(y_train)\n",
    "            dfy_test_ls.append(y_test)\n",
    "\n",
    "        print(f'k-fold split w/k folds: {k}')\n",
    "        print(f'Per Split || y_classes: {dfy_train_ls[0].shape[1]} | x_features: {dfx_train_ls[0].shape[1]} | n-train: {dfx_train_ls[0].shape[0]} | n-test: {dfx_test_ls[0].shape[0]}')\n",
    "    # print shape\n",
    "\n",
    "    if k == 0: # return original + train/test dfs\n",
    "        return df, dfx_train, dfx_test, dfy_train, dfy_test\n",
    "    else: # return original + tarin/test df lists\n",
    "        return df, dfx_train_ls, dfx_test_ls, dfy_train_ls, dfy_test_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n# IMPROVEMENT NOTES\\n- values 1 and 2 in a column turn into seperate columns instead of becoming 0 and 1? factorise first? test it\\n- how to better treat missing \\'?\\' values in the data sets?\\n- double check how the drop and binning works based on how you select y - when at beginning or at end\\n-- e.g. for flags y is in the middle - how does that affect the indexing?\\n- impute missing ? values when factorising? how would that work - bridges is like this\\n\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_load(dataset, print_out=0, test_size=0.3, k=0, n=0, seed_val=123):\n",
    "    print_out = print_out # print prep details\n",
    "    \n",
    "    if dataset=='zoo':\n",
    "        file_path = './data/zoo/zoo.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 17 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0, 0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "    \n",
    "    if dataset=='student':\n",
    "        file_path = './data/student/DATA.csv'\n",
    "        header = 0 # None or 0 (first row)\n",
    "        delimiter = ';' # None = ',' or pass str if something\n",
    "        col_y_idx0 = 32 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0, 0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "\n",
    "    if dataset=='phishing':\n",
    "        file_path = './data/phishing/PhishingData.csv'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 9 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "        \n",
    "    if dataset=='heart':\n",
    "        file_path = './data/heart/processed.cleveland.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 13 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {3:20, 4:20, 7:20, 9:20} # colname, bins\n",
    "\n",
    "    if dataset=='wine':\n",
    "        file_path = './data/wine/wine.data.csv'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 0 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {1:2,2:2,3:2,4:2,5:2,6:2,7:2,8:2,9:2,10:5,11:5,12:5} # colname, bins\n",
    "        \n",
    "    if dataset=='glass':\n",
    "        file_path = './data/glass/glass.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 10 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0, 0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {1:10,2:10,3:10,4:10,5:5,6:10,7:5,8:5} # colname, bins\n",
    "        \n",
    "    if dataset=='nist': # NEED TO FIX UP! only using training data here, not test file\n",
    "        file_path = './data/nist/optdigits.tra'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 64 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        # bin_cols_dict = {1:5,2:5,3:5,4:5,5:5,6:5,7:5,8:5} # colname, bins\n",
    "        bin_cols_dict = {x:4 for x in range(64)} # colname, bins\n",
    "\n",
    "    if dataset=='post-operative':\n",
    "        file_path = './data/post-operative/post-operative.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 8 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "\n",
    "    if dataset=='flag': # predicting language\n",
    "        file_path = './data/flag/flag.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 5 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0, 0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "        \n",
    "    if dataset=='balance':\n",
    "        file_path = './data/balance/balance-scale.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 0 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "        \n",
    "    if dataset=='hayes-roth':\n",
    "        file_path = './data/hayes-roth/hayes-roth.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 5 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0, 0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "        \n",
    "    if dataset=='lymphography':\n",
    "        file_path = './data/lymphography/lymphography.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 0 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "\n",
    "    if dataset=='dermatology':\n",
    "        file_path = './data/dermatology/dermatology.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 34 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "\n",
    "    if dataset=='lenses':\n",
    "        file_path = './data/lenses/lenses.csv'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 5 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0, 0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {} # colname, bins\n",
    "    \n",
    "    # NOT USING ATM - too large to load\n",
    "    if dataset=='cover':\n",
    "        file_path = './data/cover/covtype.data'\n",
    "        header = None # None or 0 (first row)\n",
    "        delimiter = None # None = ',' or pass str if something\n",
    "        col_y_idx0 = 54 # col num (ind 0) that has predicted class from df\n",
    "        dfx_col_idx0_drop_ls = [col_y_idx0] # y column and any other idx if need be\n",
    "        bin_cols_dict = {1:5,2:5,3:5,4:5,5:5,6:5,7:5,8:5, 9:5, 10:5} # colname, bins\n",
    "    \n",
    "    # load prepared data\n",
    "    returned_data = data_prepare(file_path, header, col_y_idx0, dfx_col_idx0_drop_ls, \n",
    "                                 bin_cols_dict, delimiter, print_out, \n",
    "                                 test_size, k, n, seed_val)\n",
    "    \n",
    "    (df, dfx_train, dfx_test, dfy_train, dfy_test) = returned_data\n",
    "    if print_out == 1:\n",
    "        print(f\"loaded: {dataset}\")\n",
    "    return df, dfx_train, dfx_test, dfy_train, dfy_test\n",
    "    \n",
    "# df, dfx_train, dfx_test, dfy_train, dfy_test = load_data('dermatology', print_out=0)\n",
    "# df, dfx_train_ls, dfx_test_ls, dfy_train_ls, dfy_test_ls = load_data('dermatology', print_out=1, test_size=0.3, k=0)\n",
    "\n",
    "\"\"\"\"\n",
    "# IMPROVEMENT NOTES\n",
    "- values 1 and 2 in a column turn into seperate columns instead of becoming 0 and 1? factorise first? test it\n",
    "- how to better treat missing '?' values in the data sets?\n",
    "- double check how the drop and binning works based on how you select y - when at beginning or at end\n",
    "-- e.g. for flags y is in the middle - how does that affect the indexing?\n",
    "- impute missing ? values when factorising? how would that work - bridges is like this\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_info():\n",
    "    \n",
    "    datasets = ['zoo', 'student', 'phishing', 'heart', 'wine', \n",
    "                'glass', 'nist', 'post-operative', \n",
    "                'flag', 'balance', 'hayes-roth', 'lymphography', 'dermatology'\n",
    "                ,'lenses'\n",
    "                ]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        df, dfx_train, dfx_test, dfy_train, dfy_test = data_load(dataset, print_out=0)\n",
    "        \n",
    "        print(f'dataset: {dataset: <15} | y_classes: {dfy_train.shape[1]: <5} | x_features: {dfx_train.shape[1]: <5} | n-train: {dfx_train.shape[0]: <5} | n-test: {dfx_test.shape[0]: <5}')\n",
    "\n",
    "    return dfy_train.shape[1], dfx_train.shape[1], dfx_train.shape[0], dfx_test.shape[0]\n",
    "# data_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODEL #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimize(model, cb, m_console, m_time, threads, caller='model_optimize'):\n",
    "    \n",
    "    global log_folder # get log folder from global var\n",
    "\n",
    "    # Gurobi-specific\n",
    "    model.Params.LogToConsole = m_console\n",
    "    model.Params.Threads = threads\n",
    "    model.Params.TimeLimit = m_time # seconds\n",
    "    model.Params.LogFile = log_folder + f\"model_optimize-{caller}.log\"\n",
    "    lp_path = log_folder + f\"model_optimize-{caller}.lp\"\n",
    "    # m.Params.IntFeasTol = 0.00000001  # make sure dec vars are integer (but extra work, disable if not needed)\n",
    "\n",
    "    # lazyYN = 0 # to cut or not to cut\n",
    "\n",
    "    if cb:\n",
    "        log_model_optimize(\"Lazy Con: ON\")\n",
    "        model.Params.lazyConstraints = 1\n",
    "        \n",
    "        model.update()\n",
    "        model.write(lp_path)\n",
    "        model._vars = model.getVars() # has to be right before optimize (stores variables in object m)\n",
    "        model.optimize(add_cuts)\n",
    "        \n",
    "        log_model_optimize(f\"Optimised - caller: {caller}\")\n",
    "\n",
    "    else:\n",
    "        log_model_optimize(\"Lazy Con: OFF\")\n",
    "        model.update()\n",
    "        model.write(lp_path)\n",
    "        model.optimize()\n",
    "        \n",
    "        log_model_optimize(f\"Optimised - caller: {caller}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_info_grb(model):\n",
    "\n",
    "    # global m2\n",
    "    \n",
    "    info_all = {}\n",
    "    info_all[\"objective\"] = model.ObjVal\n",
    "    info_all[\"bound\"] = model.ObjBound\n",
    "    # info_all[\"gap\"] = model.MIPGap\n",
    "    info_all[\"is_optimal\"] = (model.status == GRB.OPTIMAL)\n",
    "    info_all[\"num_nodes\"] = model.NodeCount\n",
    "    info_all[\"num_vars\"] = model.NumIntVars + model.NumBinVars\n",
    "    info_all[\"sol_count\"] = model.SolCount\n",
    "\n",
    "    if model.SolCount > 0:\n",
    "        print(\"objective: %0.2f\"%info_all[\"objective\"])\n",
    "        print(\"bound: %0.2f\"%info_all[\"bound\"])\n",
    "        print(\"gap: %0.2f\"%info_all[\"gap\"])\n",
    "        print(\"sol_count: %0.0f\"%info_all[\"sol_count\"])\n",
    "        \n",
    "    return info_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(dfx, dfy, alpha=2, beta=5, beta_dict={}):\n",
    "    \n",
    "    ############################# INITIALISE MODEL #############################\n",
    "    global m\n",
    "    m = gp.Model('BLR')\n",
    "\n",
    "    ############################# VARIABLES #############################\n",
    "    ins_count = len(dfx) # number of instances in dataset\n",
    "    # print(ins_count)\n",
    "\n",
    "    ############################## OBJECTIVE CONTENTS #############################\n",
    "    objective_ls = []\n",
    "\n",
    "    ############################# BIAS #############################\n",
    "    # testing\n",
    "    # global bias_dict\n",
    "    # global bias_bit_dict\n",
    "    # global bias_bit_equ_dict\n",
    "    # global bias_bit_class_equ_dict\n",
    "    # global wpos_dict\n",
    "    # global wneg_dict\n",
    "    # global wnet_dict\n",
    "    \n",
    "    bias_dict = {}\n",
    "    bias_bit_dict = {}\n",
    "    bias_bit_equ_dict = {}\n",
    "    bias_bit_class_equ_dict = {}\n",
    "\n",
    "    # for each class\n",
    "    for class_name2 in dfy: # one hot encoded so column names unique class names\n",
    "        \n",
    "        ### BIAS INTEGER ###\n",
    "        \n",
    "        # dec var\n",
    "        bias = m.addVar(vtype=GRB.INTEGER, name=f\"bias_c-{class_name2}\")\n",
    "        bias_dict[(class_name2)] = bias\n",
    "\n",
    "        ### BIAS BITS ###\n",
    "        \n",
    "        # bounds\n",
    "        \n",
    "        feature_ls = [x for x in dfx]\n",
    "        feature_count = len(feature_ls)\n",
    "        bias_ub =  feature_count # has be multiples of 4 less 1 for Q to be whole\n",
    "        bias_lb = -(feature_count+1)\n",
    "        # print(f\"bias_ub: {bias_ub}, bias_lb: {bias_lb}\")\n",
    "        bias_bit_class_equ = 0 # don't add bias_lb here! as added below!\n",
    "        \n",
    "        # Q formula\n",
    "        Q_val = int(math.ceil(math.log2(bias_ub-bias_lb + 1)))\n",
    "        # print(Q_val)\n",
    "\n",
    "        \n",
    "        for bit in range ( 1, Q_val + 1 ): # add to correct indexing for formula\n",
    "            # print(bit)\n",
    "            \n",
    "            # DEC VAR\n",
    "                \n",
    "            # build formula\n",
    "            bias_bit = m.addVar(vtype=GRB.BINARY, name=f\"biasbit_c-{class_name2}_b-{bit}\")\n",
    "            bias_bit_equ = int( 2**(bit-1) ) * bias_bit\n",
    "            \n",
    "            # add to dicts for tracking\n",
    "            bias_bit_dict[(class_name2, bit)] = bias_bit\n",
    "            bias_bit_equ_dict[(class_name2, bit)] = bias_bit_equ\n",
    "            \n",
    "            # add to sumation\n",
    "            bias_bit_class_equ = bias_bit_class_equ + bias_bit_equ\n",
    "\n",
    "        # CONSTRAINT\n",
    "        bias_bit_con1 = m.addConstr( bias_lb + bias_bit_class_equ <= bias_ub , name=f\"biasbit1_con_c-{class_name2}\")\n",
    "        bias_bit_con2 = m.addConstr( bias_lb + bias_bit_class_equ == bias , name=f\"biasbit2_con_c-{class_name2}\")\n",
    "        \n",
    "        # add to dict for tracking\n",
    "        bias_bit_class_equ_dict[(class_name2)] = bias_bit_class_equ\n",
    "\n",
    "    ############################# PREDICTION FOR CLASS #############################\n",
    "    y_ci_dict = {}\n",
    "\n",
    "    # for each class\n",
    "    for class_name3 in dfy: # one hot encoded so column names unique class names\n",
    "        # for each instance\n",
    "        for instance_num33 in range(ins_count):\n",
    "            # dec var\n",
    "            y_ci = m.addVar(vtype=GRB.INTEGER, name=f\"y_ci_c-{class_name3}_i-{instance_num33}\")\n",
    "            y_ci_dict[(class_name3, instance_num33)] = y_ci\n",
    "            \n",
    "    ############################# MIS/CLASSIFICATION MARGIN #############################-\n",
    "    epos_dict = {}\n",
    "    eneg_dict = {}\n",
    "\n",
    "    # for each instance\n",
    "    for instance_num4 in range(ins_count):\n",
    "        # dec var\n",
    "        # epos = m.addVar(vtype=GRB.CONTINUOUS, name=f\"epos_i-{instance_num4}\") # was continous in original code\n",
    "        epos = m.addVar(vtype=GRB.INTEGER, name=f\"epos_i-{instance_num4}\")\n",
    "        epos_dict[(instance_num4)] = epos\n",
    "        \n",
    "        # eneg = m.addVar(vtype=GRB.CONTINUOUS, name=f\"eneg_i-{instance_num4}\") # was continous in original code\n",
    "        eneg = m.addVar(vtype=GRB.INTEGER, name=f\"eneg_i-{instance_num4}\")\n",
    "        eneg_dict[(instance_num4)] = eneg\n",
    "        \n",
    "        # con 7\n",
    "        m.addConstr(epos >= 0, name=f\"epos_con7_i-{instance_num4}\")\n",
    "        m.addConstr(eneg >= 0, name=f\"eneg_con7_i-{instance_num4}\")\n",
    "        \n",
    "        # add to objective list\n",
    "        objective_ls.append( -1 * alpha * epos )\n",
    "        \n",
    "        # custom hyper parameter value\n",
    "        if instance_num4 in beta_dict: # if have a custom value for this instance\n",
    "            objective_ls.append( beta_dict[(instance_num4)] * eneg )\n",
    "        else: # otherwise use standard\n",
    "            objective_ls.append( beta * eneg )\n",
    "        \n",
    "    ############################# WEIGHTS (pos and neg and net) #############################\n",
    "    wpos_dict = {}\n",
    "    wneg_dict = {}\n",
    "    wnet_dict = {}\n",
    "\n",
    "    # wsub_dict = {}\n",
    "    \n",
    "    # for each feature\n",
    "    for feature_name5 in dfx: # cols of dfx are the feature names (0+)\n",
    "        # for each class\n",
    "        for class_name55 in dfy: # one hot encoded so column names unique class names\n",
    "            # dec var\n",
    "            wpos = m.addVar(vtype=GRB.BINARY, name=f\"wpos_f-{feature_name5}_c-{class_name55}\")\n",
    "            wpos_dict[(feature_name5, class_name55)] = wpos\n",
    "            \n",
    "            wneg = m.addVar(vtype=GRB.BINARY, name=f\"wneg_f-{feature_name5}_c-{class_name55}\")\n",
    "            wneg_dict[(feature_name5, class_name55)] = wneg\n",
    "            \n",
    "            # wnet recorded for con3 later on\n",
    "            wnet = wpos - wneg\n",
    "            wnet_dict[(feature_name5, class_name55)] = wnet\n",
    "                    \n",
    "            # con 2\n",
    "            m.addConstr(wpos + wneg <= 1, name=f\"wcon2_f-{feature_name5}_c-{class_name55}\")\n",
    "            \n",
    "            # add to objective list\n",
    "            objective_ls.append(wpos)\n",
    "            objective_ls.append(wneg)\n",
    "\n",
    "    ############################# CONSTRAINT 3 + 4 #############################\n",
    "    con3_dict = {}\n",
    "    con4_dict = {}\n",
    "    \n",
    "    for instance_num6 in range(ins_count):\n",
    "        for class_name66 in dfy: # one hot encoded so column names unique class names\n",
    "            \n",
    "            # CON 3\n",
    "            con3_equ = 0\n",
    "            \n",
    "            # iterature features and sum\n",
    "            for feature_name66 in dfx: # cols of dfx are the feature names (0+)\n",
    "                if dfx[feature_name66][instance_num6] == 1: # only add weights where x_fi = 1 (instance and feature)\n",
    "                    # con3_equ = con3_equ + wpos_dict[(feature_name66,class_name66)] - wnet_dict[(feature_name66,class_name66)]\n",
    "                    con3_equ = con3_equ + wnet_dict[(feature_name66,class_name66)]\n",
    "                \n",
    "            # add bias for each class\n",
    "            con3_equ = con3_equ + bias_dict[(class_name66)]\n",
    "            \n",
    "            # add contraint (equation = ypred)\n",
    "            con3 = m.addConstr(con3_equ == y_ci_dict[(class_name66, instance_num6)] , name=f\"con3_c-{class_name66}_i-{instance_num6}\")\n",
    "            con3_dict[(class_name66, instance_num6)] = con3\n",
    "            \n",
    "            \n",
    "            # CON 4\n",
    "            \n",
    "            # if class does not equal the output class\n",
    "            dfy_cold_enc = dfy.idxmax(axis=1) # undo 1 hot encoding\n",
    "            y_label_class_name = dfy_cold_enc.loc[instance_num6]\n",
    "            \n",
    "            if class_name66 != y_label_class_name: # for all other (incorrect) classes\n",
    "                \n",
    "                con4 = m.addConstr( y_ci_dict[(y_label_class_name, instance_num6)] >= y_ci_dict[(class_name66, instance_num6)] + epos_dict[(instance_num6)] - eneg_dict[(instance_num6)] , name=f\"con4_c-{class_name66}_i-{instance_num6}\")\n",
    "                con4_dict[(class_name66, instance_num6)] = con4\n",
    "            \n",
    "\n",
    "    ############################# OBJECTIVE #############################\n",
    "\n",
    "    # test con (all weights cannot be 0!)\n",
    "    # pos_con99 = m.addConstr( gp.quicksum( [v for v in wpos_dict.values()] ) >=1, name=\"pos_con99\" )\n",
    "    # neg_con99 = m.addConstr( gp.quicksum( [v for v in wneg_dict.values()] ) >=1, name=\"neg_con99\" )\n",
    "    \n",
    "    objective_full = sum([x for x in objective_ls])\n",
    "    m.setObjective(objective_full, GRB.MINIMIZE)\n",
    "    \n",
    "    return m, epos_dict, eneg_dict, wpos_dict, wneg_dict, wnet_dict, bias_dict, bias_bit_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST model_build()\n",
    "testing = 0\n",
    "if testing:\n",
    "\n",
    "    # df, dfx_train, dfx_test, dfy_train, dfy_test = data_load('student')\n",
    "    # df, dfx_train, dfx_test, dfy_train, dfy_test = data_load('nist')\n",
    "    # df, dfx_train, dfx_test, dfy_train, dfy_test = data_load('lenses')\n",
    "    df, dfx_train, dfx_test, dfy_train, dfy_test = data_load('wine', print_out=1)\n",
    "    # df, dfx_train, dfx_test, dfy_train, dfy_test = data_load('cover')\n",
    "\n",
    "    alpha = 2\n",
    "    beta = 5\n",
    "    beta_dict = {1: 11, 2:22}\n",
    "    ret_test_model_build = model_build(dfx_train, dfy_train, alpha, beta, beta_dict)\n",
    "    (m, epos_dict, eneg_dict, wpos_dict, wneg_dict, wnet_dict, bias_dict, bias_bit_dict) = ret_test_model_build \n",
    "    cb = 0\n",
    "    m_console = 0\n",
    "    m_time = 5\n",
    "    threads = 10\n",
    "    model_optimize(m, cb, m_console, m_time, threads, caller='test_model_build')\n",
    "\n",
    "    # Training + Test Accuracy\n",
    "    training_accuracy, training_pred_outcome = model_accuracy(bias_dict, wpos_dict, wneg_dict, dfx_train, dfy_train)\n",
    "    test_accuracy, test_pred_outcome = model_accuracy(bias_dict, wpos_dict, wneg_dict, dfx_test, dfy_test)\n",
    "    print(f'Training Accuracy: {training_accuracy} | Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cuts(m, where):\n",
    "    if where == GRB.Callback.MIPSOL:\n",
    "        \n",
    "        print(\"cb\")\n",
    "\n",
    "        # build dicts using callback solution\n",
    "        \n",
    "        wpos_dict_val = {} # val as don't have to use .X\n",
    "        wneg_dict_val = {} # val as don't have to use .X\n",
    "        bias_dict_val = {} # val as don't have to use .X\n",
    "        bias_bit_dict_val = {} # val as don't have to use .X\n",
    "        \n",
    "        wpos_dict_var = {} # vars w/o values\n",
    "        wneg_dict_var = {} # vars w/o values\n",
    "        bias_dict_var = {} # vars w/o values\n",
    "        bias_bit_dict_var = {} # vars w/o values\n",
    "        \n",
    "        for fc1, var_name1 in wpos_dict.items(): # for (feature, class) in dict\n",
    "            wpos_dict_val[fc1] = m.cbGetSolution(var_name1) # getting value, not dec var\n",
    "            \n",
    "            for var_cb in m._vars: # get vars from solution (the ones in dict you pass are not updated yet)\n",
    "                if str(var_cb) == str(var_name1):\n",
    "                    wpos_dict_var[fc1] = var_cb\n",
    "                    # print(f\"wpos_var: {var_cb}, type{type(var_cb)}\")\n",
    "\n",
    "        for fc2, var_name2 in wneg_dict.items():\n",
    "            wneg_dict_val[fc2] = m.cbGetSolution(var_name2)\n",
    "\n",
    "            for var_cb in m._vars:\n",
    "                if str(var_cb) == str(var_name2):\n",
    "                    wneg_dict_var[fc2] = var_cb\n",
    "        \n",
    "        for fc3, var_name3 in bias_dict.items():\n",
    "            bias_dict_val[fc3] = m.cbGetSolution(var_name3)\n",
    "\n",
    "            for var_cb in m._vars:\n",
    "                if str(var_cb) == str(var_name3):\n",
    "                    bias_dict_var[fc3] = var_cb\n",
    "        \n",
    "        for fc4, var_name4 in bias_bit_dict.items():\n",
    "            bias_bit_dict_val[fc4] = m.cbGetSolution(var_name4)\n",
    "\n",
    "            for var_cb in m._vars:\n",
    "                if str(var_cb) == str(var_name4):\n",
    "                    bias_bit_dict_var[fc4] = var_cb\n",
    "        \n",
    "        wcomb_dict_cb = model_wcomb(dfx_train, dfy_train, wpos_dict_val, wneg_dict_val, cb=True)\n",
    "        \n",
    "        # check if all weights null in solution (may be in initial solution) = True if null\n",
    "        wcomb_null = all(value == 0 for value in wcomb_dict_cb.values())\n",
    "        \n",
    "        # if weights not null continue\n",
    "        if wcomb_null:\n",
    "            print(\"solution found : null weights\")\n",
    "            pass\n",
    "        else:\n",
    "            print(\"solution found : not-null weights\")\n",
    "            # print('wcomb_dict_cb:\\n',wcomb_dict_cb)\n",
    "            # print(wcomb_dict_cb)\n",
    "            # check for adv example (status = 1 if found, else 0)\n",
    "            ibudget = 3\n",
    "            gbudget = 2\n",
    "            msub_console = 0\n",
    "            msub_time = 10\n",
    "            itr_num = 999\n",
    "            count_miss = 0\n",
    "            score_threshold = 1\n",
    "            adv_idx_ls = [1,2,3]\n",
    "            wbudget = 3\n",
    "            \n",
    "            # pass val dict! \n",
    "            ret_adv_example_gen = adv_example_gen(dfx_train, dfy_train, wpos_dict, wneg_dict, bias_dict, bias_bit_dict, \n",
    "                                                  ibudget, adv_idx_ls, wbudget, msub_console, msub_time,\n",
    "                                                  threads, itr_num, count_miss, score_threshold, cb=True)\n",
    "            (adv_status, adv_count) = ret_adv_example_gen\n",
    "            \n",
    "            if adv_status == 1: # adv example found w/existing weights\n",
    "                log_adv_train(f\"Adv example found during itr_num: {itr_num} \")\n",
    "                \n",
    "                # generate cut\n",
    "                # cut_equ_lhs, n_val_rhs = adv_cut(wpos_dict_val, wneg_dict_val, bias_bit_dict_val, cb=True)\n",
    "                cut_equ_lhs, n_val_rhs = adv_cut_cb(wpos_dict_var, wneg_dict_var, bias_bit_dict_var,\n",
    "                                                    wpos_dict_val, wneg_dict_val, bias_bit_dict_val)\n",
    "                \n",
    "                m.cbLazy( cut_equ_lhs <= n_val_rhs )\n",
    "                log_adv_train(f\" Lazy Con Added \")\n",
    "                print(f\" Lazy Con Added \")\n",
    "                # print(cut_equ_lhs)\n",
    "                # print(n_val_rhs)\n",
    "                \n",
    "                \n",
    "            #     # add cut as constraint (to master model m)\n",
    "            #     cut = m.addConstr( cut_equ_lhs <= nval_rhs , name=f\"cut-{cut_num}\" )\n",
    "            #     cut_num = cut_num + 1\n",
    "            #     cut_dict[cut_num] = cut\n",
    "            #     log_adv_train(f\"added cut : {cut_num}\")\n",
    "        \n",
    "        print(adv_status, adv_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Bias Bits\n",
    "testing = 0\n",
    "\n",
    "# MAKE DICTS GLOBAL IN model_build() to test\n",
    "\n",
    "if testing:\n",
    "    \n",
    "    # bias_bit_dict\n",
    "    print(\"bias_dict\")\n",
    "    bias_val = 0\n",
    "    for (k, v) in bias_dict.items():\n",
    "        print(k,v.X)\n",
    "    \n",
    "    # bias bit class\n",
    "    print(\"bias_bit_class_equ_dict\")\n",
    "    for k,v in bias_bit_class_equ_dict.items():\n",
    "        print(k, v.getValue())\n",
    "    \n",
    "    # get bias val from bits\n",
    "    print(\"bias_bit_dict\")\n",
    "    bias_val = 0\n",
    "    for (k, v) in bias_bit_dict.items():\n",
    "        print(k,v.X)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_wcomb(dfx, dfy, wpos_dict, wneg_dict, cb=False):\n",
    "    \n",
    "    # make weights dict (combining pos + neg weights)\n",
    "    \n",
    "    wcomb_dict = {}\n",
    "\n",
    "    # for each feature\n",
    "    for i1, feature_name1 in enumerate(dfx):\n",
    "        \n",
    "        # for each class\n",
    "        for i2, class_name2 in enumerate(dfy): # one hot encoded so column names unique class names\n",
    "            \n",
    "            # when from callback already have value (no .X)\n",
    "            if cb == False:\n",
    "                \n",
    "                if wpos_dict[(feature_name1, class_name2)].X == 1:\n",
    "                    # print(feature_name3, class_name5)\n",
    "                    wcomb_dict[feature_name1, class_name2] = 1\n",
    "                    pass\n",
    "\n",
    "                elif wneg_dict[(feature_name1, class_name2)].X == 1:\n",
    "                    # print(feature_name3, class_name5)\n",
    "                    wcomb_dict[feature_name1, class_name2] = -1\n",
    "                    pass\n",
    "                \n",
    "                else: # both weights are zero\n",
    "                    # print(feature_name3, class_name5)\n",
    "                    wcomb_dict[feature_name1, class_name2] = 0\n",
    "                    pass\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if wpos_dict[(feature_name1, class_name2)] == 1:\n",
    "                    # print(feature_name3, class_name5)\n",
    "                    wcomb_dict[feature_name1, class_name2] = 1\n",
    "                    pass\n",
    "\n",
    "                elif wneg_dict[(feature_name1, class_name2)] == 1:\n",
    "                    # print(feature_name3, class_name5)\n",
    "                    wcomb_dict[feature_name1, class_name2] = -1\n",
    "                    pass\n",
    "                \n",
    "                else: # both weights are zero\n",
    "                    # print(feature_name3, class_name5)\n",
    "                    wcomb_dict[feature_name1, class_name2] = 0\n",
    "                    pass        \n",
    "                \n",
    "            \n",
    "    return wcomb_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='pred'):\n",
    "\n",
    "        score_dict = {}\n",
    "\n",
    "        for class_num in class_ls:\n",
    "            class_score = 0\n",
    "            \n",
    "            # when from callback already have value (no .X)\n",
    "            if cb == False:\n",
    "                bias = bias_dict[(class_num)].X\n",
    "            else:\n",
    "                bias = bias_dict[(class_num)]\n",
    "                \n",
    "            class_score = class_score + bias\n",
    "                \n",
    "            for feature_num, feature_val in enumerate(x_ins):\n",
    "                weight = wcomb_dict[(feature_num, class_num)]\n",
    "                calc = feature_val * weight\n",
    "                class_score = class_score + calc\n",
    "                score_dict[class_num] = class_score\n",
    "            \n",
    "            # print(class_num, class_score)\n",
    "            \n",
    "        # print(max(score_dict, key=score_dict.get))\n",
    "\n",
    "        if ret == 'score_dict':\n",
    "            return score_dict\n",
    "        elif ret == 'score_max':\n",
    "            return max(score_dict.values()) # return value (score) of max score\n",
    "        elif ret == 'pred':\n",
    "            return max(score_dict, key=score_dict.get) # return key (class) of max score\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(bias_dict, wpos_dict, wneg_dict, dfx, dfy):\n",
    "    \n",
    "    class_ls = [x for x in dfy]\n",
    "    wcomb_dict = model_wcomb(dfx, dfy, wpos_dict, wneg_dict) # get weights combined\n",
    "    ins_count = len(dfx)\n",
    "    pred_outcome = []\n",
    "    \n",
    "    for i1, instance_num1 in enumerate( range(ins_count) ): # cycle through all training instances\n",
    "        \n",
    "        x_ins = list(dfx.loc[instance_num1]) # get instance\n",
    "        x_ins_label = dfy.idxmax(axis=1)[instance_num1] # get label\n",
    "        x_ins_pred = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='pred') # pred for x_ins\n",
    "        # print(x_ins_label)\n",
    "        # print(x_ins_pred)\n",
    "        \n",
    "        # compare\n",
    "        if x_ins_pred == x_ins_label:\n",
    "            pred_outcome.append(1.0)\n",
    "        else:\n",
    "            pred_outcome.append(0)\n",
    "\n",
    "    decimal_accu = round( mean(pred_outcome) , 4 )\n",
    "    percent_accu = round( mean(pred_outcome) * 100 , 2 )\n",
    "    \n",
    "    # print('Accuracy', mean(pred_outcome))\n",
    "    return percent_accu, pred_outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_info_acc(bias_dict, wpos_dict, wneg_dict, dfx_train, dfy_train, dfx_test, dfy_test):\n",
    "    \n",
    "    train_acc, train_pred_outcome = model_accuracy(bias_dict, wpos_dict, wneg_dict, dfx_train, dfy_train)\n",
    "    test_acc, test_pred_outcome = model_accuracy(bias_dict, wpos_dict, wneg_dict, dfx_test, dfy_test)\n",
    "    \n",
    "    print(f'Train Acc: {train_acc} | Test Acc: {test_acc} | Diff: {round(test_acc-train_acc,2)}')\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ADV #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET EXAMPLE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_example_ins(q01_dict, q10_dict, x_ins):\n",
    "    \n",
    "    x_adv = []\n",
    "    flips_ins = 0\n",
    "    \n",
    "    # for each x value\n",
    "    for i, x in enumerate(x_ins):\n",
    "        # print(x)\n",
    "        # print( f\"q01_dict[i].X: {q01_dict[i].X}\")\n",
    "        \n",
    "        if q01_dict[i].X: # if 1\n",
    "            # print(x)\n",
    "            x_adv.append(1)\n",
    "            flips_ins = flips_ins + 1\n",
    "            \n",
    "        elif q10_dict[i].X: # if 1\n",
    "            x_adv.append(0)\n",
    "            flips_ins = flips_ins + 1\n",
    "        \n",
    "        else:\n",
    "            x_adv.append(x) # original value if no flip\n",
    "            \n",
    "    # print(x_ins)\n",
    "    \n",
    "    # print('flips:',no_flips)\n",
    "    return x_adv, flips_ins\n",
    "        \n",
    "# x_ins_adv = get_adv_example(q01_dict, q10_dict, x_ins)\n",
    "# print(x_ins)\n",
    "# print(x_ins_adv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET CUT ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_cut_cb(wpos_dict_var, wneg_dict_var, bias_bit_dict_var, \n",
    "               wpos_dict_val, wneg_dict_val, bias_bit_dict_val):\n",
    "    \"\"\" build cut equation \"\"\"\n",
    "    # NOTE: val 1 -> w / val 0 -> 1-w <= n-1\n",
    "    # NOTE: var and val in diff dicts now however key (feature, class) same of both = use that to build equ\n",
    "    \n",
    "    cut_equ_wpos = 0\n",
    "    # get var + val (using var dict as base)\n",
    "    for fc1 in wpos_dict_var: # fc1 is the (feature, class)\n",
    "        wpos_var = wpos_dict_var[fc1] # get dec var\n",
    "        wpos_val = int(wpos_dict_val[fc1]) # get val - callback does not need .X\n",
    "    \n",
    "        # build equation\n",
    "        if wpos_val == 1:\n",
    "            cut_equ_wpos = cut_equ_wpos + wpos_var\n",
    "        elif wpos_val == 0:\n",
    "            cut_equ_wpos = cut_equ_wpos + (1 - wpos_var)\n",
    "        else:\n",
    "            print(\"Issue w/Positive Cut Equ\")\n",
    "            print(f\"wpos_dict_var: {wpos_dict_var}\")\n",
    "            print(f\"wpos_dict_val: {wpos_dict_val}\")\n",
    "        \n",
    "    cut_equ_wneg = 0\n",
    "    # get var + val (using var dict as base)\n",
    "    for fc2 in wneg_dict_var: # fc2 is the (feature, class)\n",
    "        wneg_var = wneg_dict_var[fc2] # get dec var\n",
    "        wneg_val = int(wneg_dict_val[fc2]) # get val - callback does not need .X\n",
    "\n",
    "        # build equation\n",
    "        if wneg_val == 1:\n",
    "            cut_equ_wneg = cut_equ_wneg + wneg_var\n",
    "        elif wneg_val == 0:\n",
    "            cut_equ_wneg = cut_equ_wneg + (1 - wneg_var)\n",
    "        else:\n",
    "            print(\"Issue w/Negative Cut Equ\")\n",
    "            print(f\"wneg_dict_var: {wneg_dict_var}\")\n",
    "            print(f\"wneg_dict_val: {wneg_dict_val}\")\n",
    "    \n",
    "    cut_equ_bias_bit = 0\n",
    "    # get var + val (using var dict as base)\n",
    "    for fc3 in bias_bit_dict_var: # fc2 is the (feature, class)\n",
    "        bias_bit_var = bias_bit_dict_var[fc3] # get dec var\n",
    "        bias_bit_val = int(bias_bit_dict_val[fc3]) # get val - callback does not need .X\n",
    "\n",
    "        # build equation\n",
    "        if bias_bit_val == 1:\n",
    "            cut_equ_bias_bit = cut_equ_bias_bit + bias_bit_var\n",
    "        elif bias_bit_val == 0:\n",
    "            cut_equ_bias_bit = cut_equ_bias_bit + (1 - bias_bit_var)\n",
    "        else:\n",
    "            print(\"Issue w/Negative Cut Equ\")\n",
    "            print(f\"wneg_dict_var: {bias_bit_dict_var}\")\n",
    "            print(f\"wneg_dict_val: {bias_bit_dict_val}\")\n",
    "\n",
    "    # LHS\n",
    "    # cut_equ_lhs = cut_equ_wpos + cut_equ_wneg + cut_equ_bias_bit\n",
    "    cut_equ_lhs = cut_equ_wpos + cut_equ_wneg\n",
    "\n",
    "    # RHS\n",
    "    # n_val_rhs = len(wpos_dict_var) + len(wneg_dict_var) + len(bias_bit_dict_var) - 1\n",
    "    n_val_rhs = len(wpos_dict_var) + len(wneg_dict_var) - 1\n",
    "\n",
    "    # print(cut_equ_wpos)\n",
    "    # print(cut_equ_wneg)\n",
    "    # print(cut_equ_lhs)\n",
    "    # print(n_val_rhs)\n",
    "    \n",
    "    return cut_equ_lhs, n_val_rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_cut_v0(wpos_dict, wneg_dict, bias_bit_dict):\n",
    "    \"\"\" build cut equation \"\"\"\n",
    "    # val 1 -> w / val 0 -> 1-w <= n-1\n",
    "    \n",
    "    int_sum = 0 # sum the integers (for checking)\n",
    "    \n",
    "    cut_equ_wpos = 0\n",
    "    for k_pos, v_pos in wpos_dict.items():\n",
    "        wpos_k = k_pos\n",
    "        wpos_var = v_pos\n",
    "        wpos_val = int(v_pos.X)\n",
    "        \n",
    "        if wpos_val == 1:\n",
    "            cut_equ_wpos = cut_equ_wpos + wpos_var\n",
    "        elif wpos_val == 0:\n",
    "            cut_equ_wpos = cut_equ_wpos + (1 - wpos_var)\n",
    "            int_sum = int_sum + 1\n",
    "        else:\n",
    "            print(\"Issue\")\n",
    "        # print(wpos_val)\n",
    "\n",
    "    cut_equ_wneg = 0\n",
    "    for k_neg, v_neg in wneg_dict.items():\n",
    "        wneg_k = k_neg\n",
    "        wneg_var = v_neg\n",
    "        wneg_val = int(v_neg.X)\n",
    "            \n",
    "        if wneg_val == 1:\n",
    "            cut_equ_wneg = cut_equ_wneg + wneg_var\n",
    "        elif wneg_val == 0:\n",
    "            cut_equ_wneg = cut_equ_wneg + (1 - wneg_var)\n",
    "            int_sum = int_sum + 1\n",
    "        else:\n",
    "            print(\"Issue\")\n",
    "        # print(wneg_val)\n",
    "\n",
    "    cut_equ_bias_bit = 0\n",
    "    for k_bias, v_bias in bias_bit_dict.items():\n",
    "        bias_k = k_bias\n",
    "        bias_var = v_bias\n",
    "        bias_val = int(v_bias.X)\n",
    "        \n",
    "        if bias_val == 1:\n",
    "            cut_equ_bias_bit = cut_equ_bias_bit + bias_var\n",
    "        elif bias_val == 0:\n",
    "            cut_equ_bias_bit = cut_equ_bias_bit + (1 - bias_var)\n",
    "            int_sum = int_sum + 1\n",
    "        else:\n",
    "            print(\"Issue\")\n",
    "            \n",
    "        # print(bias_val)\n",
    "        # print(bias_bit_dict)\n",
    "\n",
    "    # LHS\n",
    "    # cut_equ_lhs = cut_equ_wpos + cut_equ_wneg + cut_equ_bias_bit\n",
    "    cut_equ_lhs = cut_equ_wpos + cut_equ_wneg\n",
    "\n",
    "    # RHS\n",
    "    # n_val_rhs = len(wpos_dict) + len(wneg_dict) + len(bias_bit_dict) - 1\n",
    "    n_val_rhs = len(wpos_dict) + len(wneg_dict) - 1\n",
    "\n",
    "    # print(cut_equ_wpos)\n",
    "    # print(cut_equ_wneg)\n",
    "    # print(cut_equ_lhs)\n",
    "    # print(n_val)\n",
    "    # print(int_sum)\n",
    "    \n",
    "    return cut_equ_lhs, n_val_rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adv_cut_v1(wpos_dict, wneg_dict, bias_bit_dict, x_ins_label, x_adv_pred):\n",
    "    \"\"\" build cut equation - only for label and adv class weights \"\"\"\n",
    "    # val 1 -> w / val 0 -> 1-w <= n-1\n",
    "    \n",
    "    int_sum = 0 # sum the integers (for checking)\n",
    "    \n",
    "    cut_equ_wpos = 0\n",
    "    for k_pos, v_pos in wpos_dict.items():\n",
    "        wpos_k = k_pos\n",
    "        wpos_var = v_pos\n",
    "        wpos_val = int(v_pos.X)\n",
    "        wpos_feature = k_pos[0]\n",
    "        wpos_class = k_pos[1]\n",
    "        \n",
    "        if wpos_class == x_ins_label or wpos_class == x_adv_pred:\n",
    "            \n",
    "            if wpos_val == 1:\n",
    "                cut_equ_wpos = cut_equ_wpos + wpos_var\n",
    "            elif wpos_val == 0:\n",
    "                cut_equ_wpos = cut_equ_wpos + (1 - wpos_var)\n",
    "                int_sum = int_sum + 1\n",
    "            else:\n",
    "                print(\"Issue\")\n",
    "            # print(wpos_val)\n",
    "\n",
    "    cut_equ_wneg = 0\n",
    "    for k_neg, v_neg in wneg_dict.items():\n",
    "        wneg_k = k_neg\n",
    "        wneg_var = v_neg\n",
    "        wneg_val = int(v_neg.X)\n",
    "        wneg_feature = k_neg[0]\n",
    "        wneg_class = k_neg[1]\n",
    "\n",
    "        if wneg_class == x_ins_label or wpos_class == x_adv_pred:\n",
    "\n",
    "            if wneg_val == 1:\n",
    "                cut_equ_wneg = cut_equ_wneg + wneg_var\n",
    "            elif wneg_val == 0:\n",
    "                cut_equ_wneg = cut_equ_wneg + (1 - wneg_var)\n",
    "                int_sum = int_sum + 1\n",
    "            else:\n",
    "                print(\"Issue\")\n",
    "            # print(wneg_val)\n",
    "\n",
    "    cut_equ_bias_bit = 0\n",
    "    for k_bias, v_bias in bias_bit_dict.items():\n",
    "        bias_k = k_bias\n",
    "        bias_var = v_bias\n",
    "        bias_val = int(v_bias.X)\n",
    "        bias_feature = k_bias[0]\n",
    "        bias_class = k_bias[1]\n",
    "        \n",
    "        if bias_class == x_ins_label or wpos_class == x_adv_pred:\n",
    "            \n",
    "            if bias_val == 1:\n",
    "                cut_equ_bias_bit = cut_equ_bias_bit + bias_var\n",
    "            elif bias_val == 0:\n",
    "                cut_equ_bias_bit = cut_equ_bias_bit + (1 - bias_var)\n",
    "                int_sum = int_sum + 1\n",
    "            else:\n",
    "                print(\"Issue\")\n",
    "                \n",
    "            # print(bias_val)\n",
    "            # print(bias_bit_dict)\n",
    "\n",
    "    # LHS\n",
    "    # cut_equ_lhs = cut_equ_wpos + cut_equ_wneg + cut_equ_bias_bit\n",
    "    cut_equ_lhs = cut_equ_wpos + cut_equ_wneg # W/O BIAS\n",
    "\n",
    "    # RHS\n",
    "    # n_val_rhs = len(wpos_dict) + len(wneg_dict) + len(bias_bit_dict) - 1\n",
    "    # n_val_rhs = len(wpos_dict) + len(wneg_dict) - 1\n",
    "    n_val_rhs = cut_equ_lhs.size() - 1\n",
    "\n",
    "    # print(cut_equ_wpos)\n",
    "    # print(cut_equ_wneg)\n",
    "    # print(cut_equ_lhs)\n",
    "    # print(n_val)\n",
    "    # print(int_sum)\n",
    "    \n",
    "    return cut_equ_lhs, n_val_rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_cut_v2(dfx, dfy, x_ins, x_adv, x_ins_label, x_adv_pred, wpos_dict, \n",
    "               wneg_dict, bias_dict, bias_bit_dict, wbudget):\n",
    "    \"\"\" build cut equation \"\"\"\n",
    "    \n",
    "    # print(f\"x_label:{x_ins_label} x_adv:{x_adv_pred}\")\n",
    "    global m_third\n",
    "    m_third = gp.Model(\"Third-Problem\")\n",
    "    \n",
    "    class_ls = [x for x in dfy]\n",
    "    feature_ls = [x for x in dfx]\n",
    "    \n",
    "    # global q01pos_dict, q10pos_dict, q01neg_dict, q10neg_dict, q_vars_dict\n",
    "    \n",
    "    q01pos_dict = {} # q 0-1 flips\n",
    "    q10pos_dict = {} # q 1-0 flips\n",
    "    q01neg_dict = {} # q 0-1 flips\n",
    "    q10neg_dict = {} # q 1-0 flips\n",
    "    q_equ_other_dict = {} # q con equations for other classes (LHS)\n",
    "    q_equ_label_dict = {}  # q con equations for predicted class (RHS)\n",
    "    class_count = len(class_ls) # doesn't matter to include predicted class as gurobi will remove\n",
    "\n",
    "    q_equ_adv = 0 # q con equation for adv example (LHS)\n",
    "    q_equ_label = 0 # q con equation for label example (RHS)\n",
    "    con_budget_equ = 0 # build budget equation summing over q's for each feature\n",
    "\n",
    "    q_vars_dict = {}\n",
    "    \n",
    "    # WPOS\n",
    "    \n",
    "    ### PER FEATURE ### (q dec vars + constraints)\n",
    "    for feature_name1 in feature_ls:\n",
    "        # print(feature_name2)\n",
    "\n",
    "        q_vars_name_ls = ['q01pos_adv', 'q01neg_adv','q10pos_adv','q10neg_adv', # adv\n",
    "                          'q01pos_label','q01neg_label','q10pos_label', 'q10neg_label'] # label\n",
    "        \n",
    "        q_vars = m_third.addVars(q_vars_name_ls, vtype=GRB.BINARY, name=f\"f-{feature_name1}\")\n",
    "        q_vars_dict[(feature_name1)] = q_vars\n",
    "        # q constraints ------\n",
    "        \n",
    "        # adv\n",
    "        \n",
    "        # pos\n",
    "        m_third.addConstr( wpos_dict[(feature_name1, x_adv_pred)].X + q_vars['q01pos_adv'] - q_vars['q10pos_adv'] <= 1, name=f\"q1pos_adv_f-{feature_name1}\")\n",
    "        m_third.addConstr( wpos_dict[(feature_name1, x_adv_pred)].X + q_vars['q01pos_adv'] - q_vars['q10pos_adv'] >= 0, name=f\"q0pos_adv_f-{feature_name1}\")\n",
    "        m_third.addConstr( q_vars['q01pos_adv'] + q_vars['q10pos_adv'] <= 1, name=f\"qsumpos_adv_f-{feature_name1}\")\n",
    "        \n",
    "        # neg\n",
    "        m_third.addConstr( wneg_dict[(feature_name1, x_adv_pred)].X + q_vars['q01neg_adv'] - q_vars['q10neg_adv'] <= 1, name=f\"q1neg_adv_f-{feature_name1}\")\n",
    "        m_third.addConstr( wneg_dict[(feature_name1, x_adv_pred)].X + q_vars['q01neg_adv'] - q_vars['q10neg_adv'] >= 0, name=f\"q0neg_adv_f-{feature_name1}\")\n",
    "        m_third.addConstr( q_vars['q01neg_adv'] + q_vars['q10neg_adv'] <= 1, name=f\"qsumneg_adv_f-{feature_name1}\")\n",
    "        \n",
    "        # weight con (as in can't flip both from 0 to 1)\n",
    "        m_third.addConstr( q_vars['q01pos_adv'] + q_vars['q01neg_adv'] <= 1, name=f\"q01w_adv_f-{feature_name1}\")\n",
    "        \n",
    "        # label\n",
    "        \n",
    "        # pos\n",
    "        m_third.addConstr( wpos_dict[(feature_name1, x_ins_label)].X + q_vars['q01pos_label'] - q_vars['q10pos_label'] <= 1, name=f\"q1pos_label_f-{feature_name1}\")\n",
    "        m_third.addConstr( wpos_dict[(feature_name1, x_ins_label)].X + q_vars['q01pos_label'] - q_vars['q10pos_label'] >= 0, name=f\"q0pos_label_f-{feature_name1}\")\n",
    "        m_third.addConstr( q_vars['q01pos_label'] + q_vars['q10pos_label'] <= 1, name=f\"qsumpos_label_f-{feature_name1}\")\n",
    "\n",
    "        # neg\n",
    "        m_third.addConstr( wneg_dict[(feature_name1, x_ins_label)].X + q_vars['q01neg_label'] - q_vars['q10neg_adv'] <= 1, name=f\"q1neg_label_f-{feature_name1}\")\n",
    "        m_third.addConstr( wneg_dict[(feature_name1, x_ins_label)].X + q_vars['q01neg_label'] - q_vars['q10neg_adv'] >= 0, name=f\"q0neg_label_f-{feature_name1}\")\n",
    "        m_third.addConstr( q_vars['q01neg_label'] + q_vars['q10neg_adv'] <= 1, name=f\"qsumneg_label_f-{feature_name1}\")\n",
    "\n",
    "        # weight con (as in can't flip both from 0 to 1)\n",
    "        m_third.addConstr( q_vars['q01pos_label'] + q_vars['q01neg_label'] <= 1, name=f\"q01w_label_f-{feature_name1}\")\n",
    "        \n",
    "        # --------------------\n",
    "        \n",
    "        # build LHS and RHS equation\n",
    "        q_equ_adv = q_equ_adv + ( (wpos_dict[(feature_name1, x_adv_pred)].X + q_vars['q01pos_adv'] - q_vars['q10pos_adv'] \n",
    "                                   - wneg_dict[(feature_name1, x_adv_pred)].X + q_vars['q01neg_adv'] - q_vars['q10neg_adv']) \n",
    "                                 * x_adv[feature_name1] ) # X ADV\n",
    "        \n",
    "        q_equ_label = q_equ_label + ( (wpos_dict[(feature_name1, x_ins_label)].X + q_vars['q01pos_label'] - q_vars['q10pos_label'] \n",
    "                                       - wneg_dict[(feature_name1, x_ins_label)].X + q_vars['q01neg_label'] - q_vars['q10neg_label']) \n",
    "                                     * x_ins[feature_name1] ) # X LABEL\n",
    "        \n",
    "        # wieght flip budget\n",
    "        con_budget_equ = con_budget_equ + \\\n",
    "            q_vars['q01pos_adv'] + q_vars['q10pos_adv'] + \\\n",
    "            q_vars['q01neg_adv'] + q_vars['q10neg_adv'] + \\\n",
    "            q_vars['q01pos_label'] + q_vars['q10pos_label'] + \\\n",
    "            q_vars['q01neg_label'] + q_vars['q10neg_label']\n",
    "                \n",
    "    # Instance Level Dec Vars / Constraints (outside feature loop)\n",
    "    score_diff = m_third.addVar(vtype=GRB.INTEGER, name=f\"score_diff\")\n",
    "    m_third.addConstr( score_diff >= 0, name=f\"score_diff_con_f-{feature_name1}\") # larger than zero\n",
    "    # m_third.addConstr( score_diff <= 5, name=f\"score_diff_con2_f-{feature_name1}\") # larger than zero\n",
    "    \n",
    "    # score con (add .X of bias as var is not in this model! + just need value)\n",
    "    m_third.addConstr( q_equ_adv + bias_dict[(x_adv_pred)].X + score_diff >= q_equ_label + bias_dict[(x_ins_label)].X \n",
    "                      , name=f\"score_con\")\n",
    "    \n",
    "    m_third.update()\n",
    "    \n",
    "    # Overall Budget\n",
    "    m_third.addConstr( con_budget_equ <= wbudget, name=f\"qwbudget_con\") # total number of flips\n",
    "    # m_third.addConstr( con_budget_equ >= 1, name=f\"qsumnonzero_con\") # has to do something\n",
    "    \n",
    "    m_third.write(log_folder + 'adv_cutv2_mthird.lp')\n",
    "    \n",
    "    # objective\n",
    "    m_third.setObjective(score_diff, GRB.MINIMIZE)\n",
    "            \n",
    "    # Gurobi-specific\n",
    "    m_third.Params.LogToConsole = 0\n",
    "    m_third.Params.Threads = 10\n",
    "    m_third.Params.TimeLimit = 10\n",
    "    m_third.Params.LogFile = log_folder + 'adv_cutv2_mthird.log'\n",
    "    m_third.Params.PoolSearchMode = 2\n",
    "    \n",
    "    # m_third.Params.PoolSolutions = 100 # how many solutions to collect\n",
    "    m_third.Params.PoolSolutions = glo_PoolSolutionsN # how many solutions to collect\n",
    "    \n",
    "    m_third.optimize()\n",
    "    \n",
    "    ########################### CYCLE SOLUTIONS ########################### \n",
    "    \n",
    "    cut_equ_lhs_ls = []\n",
    "    n_val_rhs_ls = []\n",
    "    \n",
    "    # no of solutions\n",
    "    nSolutions = m_third.SolCount\n",
    "    \n",
    "    if nSolutions == 0:\n",
    "        return 0,0\n",
    "    \n",
    "    log_adv_cut_v2(f\"Number of solutions found (m_third): {nSolutions}\")\n",
    "    \n",
    "    for e in range(nSolutions):\n",
    "        m_third.setParam(GRB.Param.SolutionNumber, e)\n",
    "        log_adv_cut_v2(f\"Sol.No: {e}\")\n",
    "        \n",
    "        wpos_dict_ls_adv = [int(v.X) for k, v in wpos_dict.items() if k[1] == x_adv_pred]\n",
    "        wpos_dict_ls_label = [int(v.X) for k, v in wpos_dict.items() if k[1] == x_ins_label]\n",
    "\n",
    "        wneg_dict_ls_adv = [int(v.X) for k, v in wneg_dict.items() if k[1] == x_adv_pred]\n",
    "        wneg_dict_ls_label = [int(v.X) for k, v in wneg_dict.items() if k[1] == x_ins_label]\n",
    "\n",
    "        wpos_dict_ls_adv_out = []\n",
    "        for f, w in enumerate(wpos_dict_ls_adv):\n",
    "            # print(f, w)\n",
    "            if int(q_vars_dict[f]['q01pos_adv'].Xn) == 1:\n",
    "                wpos_dict_ls_adv_out.append(1)\n",
    "            elif int(q_vars_dict[f]['q10pos_adv'].Xn) == 1:\n",
    "                wpos_dict_ls_adv_out.append(0)\n",
    "            else:\n",
    "                wpos_dict_ls_adv_out.append(w)\n",
    "\n",
    "        wpos_dict_ls_label_out = []\n",
    "        for f, w in enumerate(wpos_dict_ls_label):\n",
    "            # print(f, w)\n",
    "            if int(q_vars_dict[f]['q01pos_label'].Xn) == 1:\n",
    "                wpos_dict_ls_label_out.append(1)\n",
    "            elif int(q_vars_dict[f]['q10pos_label'].Xn) == 1:\n",
    "                wpos_dict_ls_label_out.append(0)\n",
    "            else:\n",
    "                wpos_dict_ls_label_out.append(w)\n",
    "\n",
    "        wneg_dict_ls_adv_out = []\n",
    "        for f, w in enumerate(wneg_dict_ls_adv):\n",
    "            # print(f, w)\n",
    "            if int(q_vars_dict[f]['q01neg_adv'].Xn) == 1:\n",
    "                wneg_dict_ls_adv_out.append(1)\n",
    "            elif int(q_vars_dict[f]['q10neg_adv'].Xn) == 1:\n",
    "                wneg_dict_ls_adv_out.append(0)\n",
    "            else:\n",
    "                wneg_dict_ls_adv_out.append(w)\n",
    "\n",
    "        wneg_dict_ls_label_out = []\n",
    "        for f, w in enumerate(wneg_dict_ls_label):\n",
    "            # print(f, w)\n",
    "            if int(q_vars_dict[f]['q01neg_label'].Xn) == 1:\n",
    "                wneg_dict_ls_label_out.append(1)\n",
    "            elif int(q_vars_dict[f]['q10neg_label'].Xn) == 1:\n",
    "                wneg_dict_ls_label_out.append(0)\n",
    "            else:\n",
    "                wneg_dict_ls_label_out.append(w)\n",
    "        \n",
    "        \n",
    "        # create weight comb dict for adv and label classes only\n",
    "        wcomb_ls_adv_out = []\n",
    "        for f in feature_ls:\n",
    "            \n",
    "            if wpos_dict_ls_adv_out[f] == 1:\n",
    "                wcomb_ls_adv_out.append(1)\n",
    "            \n",
    "            elif wneg_dict_ls_adv_out[f] == 1:\n",
    "                wcomb_ls_adv_out.append(-1)\n",
    "            \n",
    "            else:\n",
    "                wcomb_ls_adv_out.append(0)\n",
    "        \n",
    "        wcomb_ls_label_out = []\n",
    "        for f in feature_ls:\n",
    "            \n",
    "            if wpos_dict_ls_label_out[f] == 1:\n",
    "                wcomb_ls_label_out.append(1)\n",
    "            \n",
    "            elif wneg_dict_ls_label_out[f] == 1:\n",
    "                wcomb_ls_label_out.append(-1)\n",
    "            \n",
    "            else:\n",
    "                wcomb_ls_label_out.append(0)\n",
    "        \n",
    "        log_adv_cut_v2(f\"wpos_dict_ls_adv: {wpos_dict_ls_adv}\")\n",
    "        log_adv_cut_v2(f\"wpos_dict_ls_adv_out: {wpos_dict_ls_adv_out}\")\n",
    "        log_adv_cut_v2(f\"above 2 diff: {wpos_dict_ls_adv!=wpos_dict_ls_adv_out}\")\n",
    "        \n",
    "        log_adv_cut_v2(f\"wpos_dict_ls_label: {wpos_dict_ls_label}\")\n",
    "        log_adv_cut_v2(f\"wpos_dict_ls_label_out: {wpos_dict_ls_label_out}\")\n",
    "        log_adv_cut_v2(f\"above 2 diff: {wpos_dict_ls_label!=wpos_dict_ls_label_out}\")\n",
    "        \n",
    "        log_adv_cut_v2(f\"wneg_dict_ls_adv: {wneg_dict_ls_adv}\")\n",
    "        log_adv_cut_v2(f\"wneg_dict_ls_adv_out: {wneg_dict_ls_adv_out}\")\n",
    "        log_adv_cut_v2(f\"above 2 diff: {wneg_dict_ls_adv!=wneg_dict_ls_adv_out}\")\n",
    "        \n",
    "        log_adv_cut_v2(f\"wneg_dict_ls_label: {wneg_dict_ls_label}\")\n",
    "        log_adv_cut_v2(f\"wneg_dict_ls_label_out: {wneg_dict_ls_label_out}\")\n",
    "        log_adv_cut_v2(f\"above 2 diff: {wneg_dict_ls_label!=wneg_dict_ls_label_out}\")\n",
    "        \n",
    "        log_adv_cut_v2(f\"wcomb_ls_adv_out: {wcomb_ls_adv_out}\")\n",
    "        log_adv_cut_v2(f\"wcomb_ls_label_out: {wcomb_ls_label_out}\")\n",
    "        log_adv_cut_v2(f\"above 2 diff: {wcomb_ls_adv_out!=wcomb_ls_label_out}\")\n",
    "        \n",
    "        # prediction\n",
    "        class_score_adv = 0\n",
    "        class_score_label = 0\n",
    "        \n",
    "        bias_adv = bias_dict[(x_adv_pred)].X\n",
    "        bias_label = bias_dict[(x_ins_label)].X\n",
    "            \n",
    "        class_score_adv = class_score_adv + bias_adv\n",
    "        class_score_label = class_score_label + bias_label\n",
    "        \n",
    "        # adv\n",
    "        for feature_num, feature_val in enumerate(x_ins):\n",
    "            calc = feature_val * wcomb_ls_adv_out[feature_num]\n",
    "            class_score_adv = class_score_adv + calc\n",
    "        # print(f\"adv: {x_adv_pred}, score: {class_score_adv}\")\n",
    "        \n",
    "        # label\n",
    "        for feature_num, feature_val in enumerate(x_ins):\n",
    "            calc = feature_val * wcomb_ls_label_out[feature_num]\n",
    "            class_score_label = class_score_label + calc\n",
    "        # print(f\"label: {x_ins_label}, score: {class_score_label}\")\n",
    "\n",
    "        # build cut equ\n",
    "        # global cut_equ_wpos, cut_equ_wneg\n",
    "        \n",
    "        cut_equ_wpos = 0\n",
    "        for k, v in wpos_dict.items():\n",
    "            wpos_k = k\n",
    "            wpos_var = v\n",
    "            wpos_feature = k[0]\n",
    "            wpos_class = k[1]\n",
    "            \n",
    "            if wpos_class == x_adv_pred:\n",
    "                \n",
    "                if wpos_dict_ls_adv_out[wpos_feature] == 1: # no need for feature loop as will go through all anyway\n",
    "                    cut_equ_wpos = cut_equ_wpos + wpos_var\n",
    "                elif wpos_dict_ls_adv_out[wpos_feature] == 0:\n",
    "                    cut_equ_wpos = cut_equ_wpos + (1 - wpos_var)\n",
    "                else:\n",
    "                    print(\"Issue\")\n",
    "                # print(wpos_val)\n",
    "                \n",
    "            if wpos_class == x_ins_label:\n",
    "                \n",
    "                if wpos_dict_ls_label_out[wpos_feature] == 1: # no need for feature loop as will go through all anyway\n",
    "                    cut_equ_wpos = cut_equ_wpos + wpos_var\n",
    "                elif wpos_dict_ls_label_out[wpos_feature] == 0:\n",
    "                    cut_equ_wpos = cut_equ_wpos + (1 - wpos_var)\n",
    "                else:\n",
    "                    print(\"Issue\")\n",
    "                # print(wpos_val)\n",
    "\n",
    "        cut_equ_wneg = 0\n",
    "        for k, v in wneg_dict.items():\n",
    "            wneg_k = k\n",
    "            wneg_var = v\n",
    "            wneg_feature = k[0]\n",
    "            wneg_class = k[1]\n",
    "            \n",
    "            if wneg_class == x_adv_pred:\n",
    "                \n",
    "                if wneg_dict_ls_adv_out[wneg_feature] == 1: # no need for feature loop as will go through all anyway\n",
    "                    cut_equ_wneg = cut_equ_wneg + wneg_var\n",
    "                elif wneg_dict_ls_adv_out[wneg_feature] == 0:\n",
    "                    cut_equ_wneg = cut_equ_wneg + (1 - wneg_var)\n",
    "                else:\n",
    "                    print(\"Issue\")\n",
    "                # print(wpos_val)\n",
    "                \n",
    "            if wneg_class == x_ins_label:\n",
    "                \n",
    "                if wneg_dict_ls_label_out[wneg_feature] == 1: # no need for feature loop as will go through all anyway\n",
    "                    cut_equ_wneg = cut_equ_wneg + wneg_var\n",
    "                elif wneg_dict_ls_label_out[wneg_feature] == 0:\n",
    "                    cut_equ_wneg = cut_equ_wneg + (1 - wneg_var)\n",
    "                else:\n",
    "                    print(\"Issue\")\n",
    "\n",
    "        cut_equ_bias_bit = 0\n",
    "        for k, v in bias_bit_dict.items():\n",
    "            bias_k = k\n",
    "            bias_var = v\n",
    "            bias_val = int(v.X)\n",
    "            bias_feature = k[0]\n",
    "            bias_class = k[1]\n",
    "            \n",
    "            if bias_class == x_adv_pred:\n",
    "                \n",
    "                if bias_val == 1:\n",
    "                    cut_equ_bias_bit = cut_equ_bias_bit + bias_var\n",
    "                elif bias_val == 0:\n",
    "                    cut_equ_bias_bit = cut_equ_bias_bit + (1 - bias_var)\n",
    "                else:\n",
    "                    print(\"Issue\")\n",
    "                # print(wpos_val)\n",
    "                \n",
    "            if bias_class == x_ins_label:\n",
    "                \n",
    "                if bias_val == 1:\n",
    "                    cut_equ_bias_bit = cut_equ_bias_bit + bias_var\n",
    "                elif bias_val == 0:\n",
    "                    cut_equ_bias_bit = cut_equ_bias_bit + (1 - bias_var)\n",
    "                else:\n",
    "                    print(\"Issue\")\n",
    "\n",
    "        # ret equations to cut\n",
    "        \n",
    "        # cut_equ_lhs = cut_equ_wpos + cut_equ_wneg + cut_equ_bias_bit # W/BIAS CUT\n",
    "        cut_equ_lhs = cut_equ_wpos + cut_equ_wneg # W/O BIAS CUT\n",
    "        \n",
    "        n_val_rhs = cut_equ_lhs.size() - 1 # isn't is just this? - size of lhs less 1?\n",
    "        \n",
    "        # append to output dict\n",
    "        cut_equ_lhs_ls.append(cut_equ_lhs)\n",
    "        n_val_rhs_ls.append(n_val_rhs)\n",
    "        \n",
    "    # print(f\"adv\", len(cut_equ_lhs_ls), len(n_val_rhs_ls))\n",
    "    return cut_equ_lhs_ls, n_val_rhs_ls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GEN EXAMPLE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_example_gen(dfx, dfy, wpos_dict, wneg_dict, bias_dict, bias_bit_dict, ibudget, adv_idx_ls, wbudget,\n",
    "                    msub_console, msub_time, threads, itr_num, count_miss, score_threshold, cb=False):\n",
    "    # Params\n",
    "    class_ls = [x for x in dfy]\n",
    "    feature_ls = [x for x in dfx]\n",
    "    wcomb_dict = model_wcomb(dfx, dfy, wpos_dict, wneg_dict, cb)\n",
    "    adv_count = 0           # count num of adv examples found / used for gbudget below\n",
    "    missclass_count = 0      # count num of misclassified samples\n",
    "    \n",
    "    # print(ins_count)\n",
    "    # print(wcomb_dict)\n",
    "    # print(len(wcomb_dict))\n",
    "    \n",
    "    # index of adv examples from dfx the sub sees\n",
    "    # adv_idx_ls = [2,3]\n",
    "    # ins_count = len(adv_idx_ls)    # number of instances in adv_idx passed\n",
    "    \n",
    "    for instance_num1 in adv_idx_ls : # cycle through all training instances \n",
    "        \n",
    "        # get x instance details\n",
    "        x_ins = list(dfx.loc[instance_num1])\n",
    "        x_ins_label = dfy.idxmax(axis=1)[instance_num1]\n",
    "        \n",
    "        # get instance prediction based on current weights/bias\n",
    "        x_ins_pred = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb, ret='pred')\n",
    "        x_ins_pred_score = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb, ret='score_max')\n",
    "        x_ins_pred_score_dict = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb, ret='score_dict')\n",
    "        \n",
    "        # log\n",
    "        log_adv_example_gen(f'################## itr_num: {itr_num} ###################') # itr_num passed from adv_train() to keep track\n",
    "        log_adv_example_gen(f'------------------ Instance Details ------------------') # itr_num passed from adv_train() to keep track\n",
    "        log_adv_example_gen(f'instance_num1: {instance_num1}')\n",
    "        log_adv_example_gen(f'label: {x_ins_label}')\n",
    "        log_adv_example_gen(f'pred: {x_ins_pred}')\n",
    "        log_adv_example_gen(f'correct: {x_ins_pred==x_ins_label}')\n",
    "        log_adv_example_gen(f'max class score: {x_ins_pred_score}')\n",
    "        log_adv_example_gen(f'all class scores: {x_ins_pred_score_dict}')\n",
    "        \n",
    "        if cb:\n",
    "            print(f'------------------ Instance Details ------------------') # itr_num passed from adv_train() to keep track\n",
    "            print(f'instance_num1: {instance_num1}')\n",
    "            print(f'label: {x_ins_label}')\n",
    "            print(f'pred: {x_ins_pred}')\n",
    "            print(f'correct: {x_ins_pred==x_ins_label}')\n",
    "            print(f'max class score: {x_ins_pred_score}')\n",
    "            print(f'all class scores: {x_ins_pred_score_dict}')\n",
    "    \n",
    "        if int(x_ins_pred) != int(x_ins_label): # if misclassfied sample\n",
    "             \n",
    "            missclass_count = missclass_count + 1\n",
    "            continue\n",
    "         \n",
    "        if int(x_ins_pred) == int(x_ins_label): # if correctly classified sample\n",
    "                        \n",
    "            # create model\n",
    "            global m_sub\n",
    "            m_sub = gp.Model(\"Sub-Problem\")\n",
    "\n",
    "            q01_dict = {} # q 0-1 flips\n",
    "            q10_dict = {} # q 1-0 flips\n",
    "            z_ind_dict = {} # dict for indicator vars\n",
    "            q_equ_other_dict = {} # q con equations for other classes (LHS)\n",
    "            q_equ_label_dict = {}  # q con equations for predicted class (RHS)\n",
    "            class_count = len(class_ls) # doesn't matter to include predicted class as gurobi will remove\n",
    "            \n",
    "            ### PER FEATURE ### (q dec vars + constraints)\n",
    "            for feature_name2 in feature_ls:\n",
    "                # print(feature_name2)\n",
    "                \n",
    "                # Dec Var\n",
    "                q01 = m_sub.addVar(vtype=GRB.BINARY, name=f\"q01_f-{feature_name2}\")\n",
    "                q01_dict[(feature_name2)] = q01\n",
    "\n",
    "                q10 = m_sub.addVar(vtype=GRB.BINARY, name=f\"q10_f-{feature_name2}\")\n",
    "                q10_dict[(feature_name2)] = q10\n",
    "                \n",
    "                # print(feature_name2, x_ins[feature_name2])\n",
    "                \n",
    "                # q flip constraints\n",
    "                m_sub.addConstr( x_ins[feature_name2] + q01 - q10 <= 1, name=f\"q1_con_f-{feature_name2}\")\n",
    "                m_sub.addConstr( x_ins[feature_name2] + q01 - q10 >= 0, name=f\"q0_con_f-{feature_name2}\")\n",
    "                m_sub.addConstr( q01 + q10 <= 1, name=f\"qsum_con_f-{feature_name2}\")\n",
    "                m_sub.update()\n",
    "                \n",
    "            ### PER CLASS ### (build LHS and RHS equations)\n",
    "            for i3, class_name3 in enumerate(class_ls):\n",
    "                \n",
    "                # print(f\"i3: {i3}, class_name3: {class_name3}\")\n",
    "                \n",
    "                q_equ_other = 0 # q con equation for other classes (LHS)\n",
    "                q_equ_label = 0 # q con equation for label class (RHS)\n",
    "                \n",
    "                # label class (adv)\n",
    "                if int(class_name3) == int(x_ins_label):\n",
    "                    continue # move onto next class as don't need to build equation for label class\n",
    "                \n",
    "                # for other classes\n",
    "                else:\n",
    "                    for i4, feature_name4 in enumerate(feature_ls): \n",
    "                        \n",
    "                        # x*q*wgt for label class\n",
    "                        wgt_f_c_label = wcomb_dict[feature_name4, x_ins_label] # use x ins label\n",
    "                        q_equ_label = q_equ_label + (x_ins[feature_name4] + q01_dict[feature_name4] - q10_dict[feature_name4]) * wgt_f_c_label\n",
    "                        \n",
    "                        # x*q*wgt for other classes                  \n",
    "                        wgt_f_c_other = wcomb_dict[feature_name4, class_name3] # use class iterating\n",
    "                        q_equ_other = q_equ_other + (x_ins[feature_name4] + q01_dict[feature_name4] - q10_dict[feature_name4]) * wgt_f_c_other\n",
    "\n",
    "                    # add bias for label class (if outside cb use .X)\n",
    "                    if cb:\n",
    "                        bias_label = bias_dict[(x_ins_label)] # use x_ins_label & bias val dict for cb\n",
    "                    else:\n",
    "                        bias_label = bias_dict[(x_ins_label)].X # use x_ins_label & bias val dict for cb\n",
    "                    q_equ_label = q_equ_label + bias_label\n",
    "                    q_equ_label_dict[x_ins_label] = q_equ_label\n",
    "                    \n",
    "                    # add bias for other classes (if outside cb use .X)\n",
    "                    if cb:\n",
    "                        bias_other = bias_dict[(class_name3)] # use class iterating & bias val dict\n",
    "                    else:\n",
    "                        bias_other = bias_dict[(class_name3)].X # use class iterating & bias val dict\n",
    "                    q_equ_other = q_equ_other + bias_other\n",
    "                    q_equ_other_dict[class_name3] = q_equ_other\n",
    "                    \n",
    "                    # add score constraint on other classes w/indicator\n",
    "                    z = m_sub.addVar( vtype=\"B\", name=f\"ind[{class_name3}]\")\n",
    "                    z_ind_dict[class_name3] = z\n",
    "                    m_sub.addConstr( (z == 1) >> (q_equ_other + score_threshold >= q_equ_label) , name=f\"score_con_c-{class_name3}\")                        \n",
    "                    \n",
    "            # at least 1 z active\n",
    "            m_sub.addConstr(gp.quicksum( [x[1] for x in z_ind_dict.items()] ) >= 1, name=\"select\")\n",
    "            \n",
    "            # total q flip budget (per instance)\n",
    "            con_budget_equ = 0 # build budget equation summing over q's for each feature\n",
    "            for feature_name5 in feature_ls:\n",
    "                con_budget_equ = con_budget_equ + q01_dict[feature_name5] + q10_dict[feature_name5]\n",
    "            m_sub.addConstr( con_budget_equ <= ibudget, name=f\"qbudget_con\")\n",
    "\n",
    "            # TEST CON (all q cannot be zero! cannot be 0!)\n",
    "            m_sub.addConstr( con_budget_equ >= 1, name=f\"qsumnonzero_con\")\n",
    "            \n",
    "            # Set Objective (for testing)\n",
    "            # m_sub.setObjective(con_budget_equ, GRB.MINIMIZE) # minimise flips\n",
    "            # m_sub.setObjective(con_budget_equ, GRB.MAXIMIZE) # minimise flips\n",
    "            # m_sub.setObjective(q_equ_other, GRB.MAXIMIZE)\n",
    "            # m_sub.setObjective(q_equ_other + score_threshold - q_equ_label, GRB.MAXIMIZE)\n",
    "            \n",
    "            # m_sub.update()\n",
    "            m_sub.write(log_folder + 'adv_example_gen_msub.lp')\n",
    "            \n",
    "            # Gurobi-specific\n",
    "            m_sub.Params.LogToConsole = msub_console\n",
    "            m_sub.Params.Threads = threads\n",
    "            m_sub.Params.TimeLimit = msub_time\n",
    "            m_sub.Params.LogFile = log_folder + 'adv_example_gen_msub.log'\n",
    "            # m_sub.Params.PoolSearchMode = 2\n",
    "            # m_sub.Params.PoolSolutions = 20\n",
    "            m_sub.optimize()\n",
    "            \n",
    "            log_adv_example_gen(\"-----------Sub-Problem Details-----------\")\n",
    "            \n",
    "            if m_sub.SolCount == 0:\n",
    "                log_adv_example_gen(f\"No solution found\")\n",
    "                log_adv_example_gen(f\"x_ins: {x_ins}\")\n",
    "                log_adv_example_gen(f\"adv_count (unchanged): {adv_count}\")\n",
    "                \n",
    "                if cb:\n",
    "                    print(f\"No solution found\")\n",
    "                    print(f\"x_ins: {x_ins}\")\n",
    "                    print(f\"adv_count (unchanged): {adv_count}\")\n",
    "                continue\n",
    "            \n",
    "            else: # if solution found\n",
    "                \n",
    "                # nSolutions = m_sub.SolCount\n",
    "                # print('Number of solutions found (m_sub): ' + str(nSolutions))\n",
    "                log_adv_example_gen(f\"A solution found\")\n",
    "                \n",
    "                # get solution details + prediction\n",
    "                x_adv, no_flips = adv_example_ins(q01_dict, q10_dict, x_ins) # get the x_adv (adv version of x_ins)\n",
    "                x_adv_pred = model_prediction(wcomb_dict, bias_dict, x_adv, class_ls, cb, ret='pred') # use x_adv\n",
    "                x_adv_pred_score_dict = model_prediction(wcomb_dict, bias_dict, x_adv, class_ls, cb, ret='score_dict')\n",
    "\n",
    "                log_adv_example_gen(f\"x_ins: {x_ins}\")\n",
    "                log_adv_example_gen(f\"x_adv: {x_adv}\")\n",
    "                log_adv_example_gen(f\"flips: {no_flips}\")\n",
    "                \n",
    "                log_adv_example_gen(f\"x_ins_pred: {x_ins_pred}\")\n",
    "                log_adv_example_gen(f\"x_ins_pred score_dict: {x_ins_pred_score_dict}\")\n",
    "                \n",
    "                log_adv_example_gen(f\"x_adv_pred: {x_adv_pred}\")\n",
    "                log_adv_example_gen(f\"x_adv_pred score_dict: {x_adv_pred_score_dict}\")\n",
    "                \n",
    "                if cb: # print\n",
    "                    print(f\"A solution found\")\n",
    "                    print(f\"x_ins: {x_ins}\")\n",
    "                    print(f\"x_adv: {x_adv}\")\n",
    "                    print(f\"flips: {no_flips}\")\n",
    "                    print(f\"x_ins_pred: {x_ins_pred}\")\n",
    "                    print(f\"x_ins_pred score_dict: {x_ins_pred_score_dict}\")\n",
    "                    print(f\"x_adv_pred: {x_adv_pred}\")\n",
    "                    print(f\"x_adv_pred score_dict: {x_adv_pred_score_dict}\")\n",
    "                \n",
    "                ### SHOW WEIGHTS (for testing/checking)\n",
    "                wpos_label_ls = []\n",
    "                wneg_label_ls = []\n",
    "                wpos_adv_ls = []\n",
    "                wneg_adv_ls = []\n",
    "                q01_ls = []\n",
    "                q10_ls = []\n",
    "                \n",
    "                if not cb: # doesn't work in cb\n",
    "                    \n",
    "                    for f_c, var in wpos_dict.items():\n",
    "                        if f_c[1] == x_ins_label:\n",
    "                            wpos_label_ls.append( int(var.X) )\n",
    "                        if f_c[1] == x_adv_pred:\n",
    "                            wpos_adv_ls.append( int(var.X) )\n",
    "                        \n",
    "                    for f_c, var in wneg_dict.items():\n",
    "                        if f_c[1] == x_ins_label:\n",
    "                            wneg_label_ls.append( int(var.X) )\n",
    "                        if f_c[1] == x_adv_pred:\n",
    "                            wneg_adv_ls.append( int(var.X) )\n",
    "                            \n",
    "                    for f, var in q01_dict.items():\n",
    "                            q01_ls.append( int(var.X) )\n",
    "                            \n",
    "                    for f, var in q10_dict.items():\n",
    "                            q10_ls.append( int(var.X) ) \n",
    "                    \n",
    "                    log_adv_example_gen(f\"label wpos ls: {wpos_label_ls}\")\n",
    "                    log_adv_example_gen(f\"label wneg ls: {wneg_label_ls}\")\n",
    "                    log_adv_example_gen(f\"label bias: {bias_dict[(x_ins_label)].X}\")\n",
    "                    \n",
    "                    log_adv_example_gen(f\"adv wpos ls: {wpos_adv_ls}\")\n",
    "                    log_adv_example_gen(f\"adv wneg ls: {wneg_adv_ls}\")\n",
    "                    log_adv_example_gen(f\"adv bias: {bias_dict[(x_adv_pred)].X}\")\n",
    "                    \n",
    "                    log_adv_example_gen(f\"label+adv w+b: {wpos_label_ls}|{wneg_label_ls}|{bias_dict[(x_ins_label)].X}|{wpos_adv_ls}|{wneg_adv_ls}|{bias_dict[(x_adv_pred)].X}\")\n",
    "                    \n",
    "                    log_adv_example_gen(f\"q01: {q01_ls}\")\n",
    "                    log_adv_example_gen(f\"q10: {q10_ls}\")\n",
    "                    \n",
    "                # check if solution changes the prediction\n",
    "                if int(x_ins_label) == int(x_adv_pred):\n",
    "                    log_adv_example_gen(f\"Solution does not change prediction\")\n",
    "                    log_adv_example_gen(f\"adv_count (unchanged): {adv_count}\")\n",
    "                    \n",
    "                    if cb: # print\n",
    "                        print(f\"Solution does not change prediction\")\n",
    "                        print(f\"adv_count (unchanged): {adv_count}\")\n",
    "                    \n",
    "                    continue # not an adv example and continue loop\n",
    "                \n",
    "                else:\n",
    "                    adv_count = adv_count + 1 # HAS TO RUN EVEN IF CALL BACK\n",
    "                    log_adv_example_gen(f\"Solution does change prediction\")\n",
    "                    log_adv_example_gen(f\"adv_count (incremented): {adv_count}\")\n",
    "                    \n",
    "                    if cb: # print\n",
    "                        print(f\"Solution does change prediction\")\n",
    "                        print(f\"adv_count (incremented): {adv_count}\")\n",
    "                    \n",
    "                    # global record of count of examples (for testing)\n",
    "                    glo_adv_ex_dict[instance_num1] = glo_adv_ex_dict.get(instance_num1, 0) + 1\n",
    "                        \n",
    "                    # get cuts\n",
    "                    cut_equ_lhs_ls = []\n",
    "                    nval_rhs_ls = []\n",
    "                    \n",
    "                    if glo_cut_v0 == True:\n",
    "                        # cut v0 (add to list as returning cuts list now)\n",
    "                        cut_equ_lhs, nval_rhs = adv_cut_v0(wpos_dict, wneg_dict, bias_bit_dict)\n",
    "                        cut_equ_lhs_ls.append(cut_equ_lhs)\n",
    "                        nval_rhs_ls.append(nval_rhs)\n",
    "                    \n",
    "                    if glo_cut_v1 == True:\n",
    "                        # cut v0 (add to list as returning cuts list now)\n",
    "                        cut_equ_lhs, nval_rhs = adv_cut_v1(wpos_dict, wneg_dict, bias_bit_dict, x_ins_label, x_adv_pred)\n",
    "                        cut_equ_lhs_ls.append(cut_equ_lhs)\n",
    "                        nval_rhs_ls.append(nval_rhs)\n",
    "                    \n",
    "                    if glo_cut_v2 == True:\n",
    "                        cut_equ_lhs_ls_wip, nval_rhs_ls_wip = adv_cut_v2(dfx, dfy, x_ins, x_adv, x_ins_label, x_adv_pred,\n",
    "                                                                wpos_dict, wneg_dict, bias_dict, bias_bit_dict, wbudget)\n",
    "                        cut_equ_lhs_ls.extend(cut_equ_lhs_ls_wip)\n",
    "                        nval_rhs_ls.extend(nval_rhs_ls_wip)    \n",
    "                    \n",
    "                    return 1, adv_count, cut_equ_lhs_ls, nval_rhs_ls # returns as soon as adv example found\n",
    "    \n",
    "    return 0, adv_count, [], [] # no adv example found (first return 0 and last adv_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST adv_example_gen()\n",
    "testing = 0\n",
    "if testing:\n",
    "    \n",
    "    clear_log_adv_example_gen()\n",
    "    clear_log_adv_train()\n",
    "    clear_log_model_optimize()\n",
    "    \n",
    "    # dataset = 'balance'\n",
    "    dataset = 'lenses'\n",
    "    # dataset = 'zoo'\n",
    "    count_miss = 0\n",
    "    ibudget = 25\n",
    "    wbudget = 2\n",
    "    adv_idx_ls = [10]\n",
    "    # gbudget = 2000 # global budget / should return with 1 more\n",
    "    df, dfx_train, dfx_test, dfy_train, dfy_test = data_load(dataset, print_out=1)\n",
    "    \n",
    "    # build original model\n",
    "    alpha = 2\n",
    "    beta = 5\n",
    "    \n",
    "    # optimise original model to get\n",
    "    cb = 0 \n",
    "    m_console = 0\n",
    "    m_time = 15\n",
    "    threads = 10\n",
    "    msub_console = 0\n",
    "    msub_time = 10\n",
    "    threads=6\n",
    "    itr_num=-1\n",
    "    score_threshold = 1\n",
    "    \n",
    "    global glo_cut_v0 # all weights\n",
    "    global glo_cut_v1 # only adv and label class\n",
    "    global glo_cut_v2 # combos of adv and label class\n",
    "    global glo_adv_ex_dict\n",
    "\n",
    "    glo_cut_v0 = False\n",
    "    glo_cut_v1 = False\n",
    "    glo_cut_v2 = False\n",
    "    glo_adv_ex_dict = {}\n",
    "\n",
    "    new_master_model = 1 # if want to rebuild or use existing global master model\n",
    "    if new_master_model:\n",
    "        # build master\n",
    "        ret_test_adv_example = model_build(dfx_train, dfy_train, alpha, beta)\n",
    "        (m, epos_dict, eneg_dict, wpos_dict, wneg_dict, wnet_dict, bias_dict, bias_bit_dict) = ret_test_adv_example \n",
    "        # optimise master\n",
    "        model_optimize(m, cb, m_console, m_time, threads)\n",
    "\n",
    "    # Training + Test Accuracy\n",
    "    training_accuracy, training_pred_outcome = model_accuracy(bias_dict, wpos_dict, wneg_dict, dfx_train, dfy_train)\n",
    "    test_accuracy, test_pred_outcome = model_accuracy(bias_dict, wpos_dict, wneg_dict, dfx_test, dfy_test)\n",
    "    print(f'Training Accuracy: {training_accuracy} | Test Accuracy: {test_accuracy}')\n",
    "    \n",
    "    \n",
    "    ret_adv_status = adv_example_gen(dfx_train, dfy_train, \n",
    "                                 wpos_dict, wneg_dict, bias_dict, bias_bit_dict,\n",
    "                                 ibudget, adv_idx_ls, wbudget,\n",
    "                                 msub_console, msub_time, threads, itr_num, count_miss, \n",
    "                                 score_threshold, cb=False)\n",
    "    \n",
    "    (adv_status, adv_count, cut_equ_lhs_ls, nval_rhs_ls) = ret_adv_status\n",
    "    \n",
    "    print(adv_count)\n",
    "    print(cut_equ_lhs_ls)\n",
    "    print(nval_rhs_ls)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAIN #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train(dfx, dfy, alpha, beta, ibudget, adv_idx_ls, wbudget, m_time, msub_time, threads, max_itr, \n",
    "              m_console, msub_console, cb, c_time, count_miss, score_threshold):\n",
    "\n",
    "    # build master model\n",
    "    returned_model = model_build(dfx, dfy, alpha, beta)\n",
    "    (m, epos_dict, eneg_dict, wpos_dict, wneg_dict, wnet_dict, bias_dict, bias_bit_dict) = returned_model\n",
    "    \n",
    "    # records\n",
    "    cut_dict = {}\n",
    "    cut_num = 0\n",
    "    wpos_upd_dict = {} # pos wghts for each iteration\n",
    "    wneg_upd_dict = {} # neg wghts for each iteration\n",
    "    itr_num = 0 # count iterations\n",
    "    \n",
    "    # breaking criterion\n",
    "    robust = False\n",
    "    \n",
    "    # for time out / time print\n",
    "    start_time = time.time() # time now when loop started\n",
    "    s=time.gmtime(start_time)\n",
    "    start_time_f = time.strftime(\"%Y-%m-%d %H:%M:%S\", s)\n",
    "    \n",
    "    end_time = time.time() + c_time # time now + time out secs = when loop should end\n",
    "    e=time.gmtime(end_time)\n",
    "    end_time_f = time.strftime(\"%Y-%m-%d %H:%M:%S\", e)\n",
    "    \n",
    "    # initial optimization\n",
    "    model_optimize(m, cb, m_console, m_time, threads, caller='adv_train')\n",
    "    log_adv_train(f\"initial optimization\")\n",
    "    log_adv_train(f\"while loop timeout: {c_time}s\")\n",
    "    log_adv_train(f\"while loop start_time: {start_time_f}\")\n",
    "    log_adv_train(f\"while loop end_time: {end_time_f}\")\n",
    "    \n",
    "    while robust == False:\n",
    "        # time.sleep(0.25) # sleep for 250 milliseconds\n",
    "        itr_num = itr_num + 1\n",
    "        log_adv_train(f'################## itr_num: {itr_num} time: {int(time.time() - start_time)}s ###################')\n",
    "        \n",
    "        # precut copy of wght + bias dicts (for testing/checking)\n",
    "        wpos_dict_precut = {}\n",
    "        wneg_dict_precut = {}\n",
    "        bias_dict_precut = {}\n",
    "\n",
    "        for f_c, var in wpos_dict.items():\n",
    "            wpos_dict_precut[f_c] = var.X\n",
    "                \n",
    "        for f_c, var in wneg_dict.items():\n",
    "            wneg_dict_precut[f_c] = var.X\n",
    "                \n",
    "        for f_c, var in bias_dict.items():\n",
    "            bias_dict_precut[f_c] = var.X\n",
    "\n",
    "        # check for adv example (status = 1 if found, else 0)\n",
    "        ret_adv_example_gen = adv_example_gen(dfx, dfy, \n",
    "                                              wpos_dict, wneg_dict, bias_dict, bias_bit_dict, \n",
    "                                              ibudget, adv_idx_ls, wbudget,\n",
    "                                              msub_console, msub_time, threads, itr_num, \n",
    "                                              count_miss, score_threshold, cb=False)\n",
    "        (adv_status, adv_count, cut_equ_lhs_ls, nval_rhs_ls) = ret_adv_example_gen\n",
    "        \n",
    "        if adv_status == 1: # adv example found w/existing weights\n",
    "            log_adv_train(f\"Adv example found during itr_num: {itr_num} \")\n",
    "            \n",
    "            # add cut as constraint (to master model m)\n",
    "            # cut_equ_lhs, nval_rhs = adv_cut(wpos_dict, wneg_dict, bias_bit_dict)\n",
    "            # cut = m.addConstr( cut_equ_lhs <= nval_rhs , name=f\"cutv1-{cut_num}\" )\n",
    "            # cut_dict[cut_num] = cut\n",
    "            # cut_num = cut_num + 1\n",
    "            \n",
    "            # log_adv_train(f\"added cut : {cut_num}\")\n",
    "            \n",
    "            # cuts\n",
    "            for cut_idx in range ( len(cut_equ_lhs_ls) ):\n",
    "                cut = m.addConstr( cut_equ_lhs_ls[cut_idx] <= nval_rhs_ls[cut_idx] , name=f\"cut_idx-{cut_idx}\" )\n",
    "                cut_dict[cut_num] = cut\n",
    "                cut_num = cut_num + 1\n",
    "                pass\n",
    "            \n",
    "            log_adv_train(f\"added cuts : {cut_num}\")\n",
    "                \n",
    "            # optimise w/new constraint\n",
    "            model_optimize(m, cb, m_console, m_time, threads, caller='adv_train')\n",
    "            log_adv_train(f\"re-optimized\")\n",
    "            log_adv_train(f\"ObjVal: {m.ObjVal} | Bound: {m.ObjBound} | Gap: {m.MIPGap} | Optimal: {m.Status==GRB.OPTIMAL}\")\n",
    "\n",
    "            # create post-cut dict (for testing/checking)\n",
    "            wpos_dict_postcut = {}\n",
    "            wneg_dict_postcut = {}\n",
    "            bias_dict_postcut = {}\n",
    "\n",
    "            for f_c, var in wpos_dict.items():\n",
    "                wpos_dict_postcut[f_c] = var.X\n",
    "                \n",
    "            for f_c, var in wneg_dict.items():\n",
    "                wneg_dict_postcut[f_c] = var.X\n",
    "\n",
    "            for f_c, var in bias_dict.items():\n",
    "                bias_dict_postcut[f_c] = var.X\n",
    "                \n",
    "            # check + report diff in weights\n",
    "            log_adv_train(\"--------------------- wgt details ---------------------\")\n",
    "            for f_c in wpos_dict:\n",
    "                if wpos_dict_postcut[f_c] != wpos_dict_precut[f_c]:\n",
    "                    log_adv_train(f\"wpos diff (f,c): {f_c} | precut: {wpos_dict_precut[f_c]} | postcut: {wpos_dict_postcut[f_c]}\")\n",
    "\n",
    "            for f_c in wneg_dict:\n",
    "                if wneg_dict_postcut[f_c] != wneg_dict_precut[f_c]:\n",
    "                    log_adv_train(f\"wneg diff (f,c): {f_c} | precut: {wneg_dict_precut[f_c]} | postcut: {wneg_dict_postcut[f_c]}\")\n",
    "            \n",
    "            for f_c in bias_dict:\n",
    "                if bias_dict_postcut[f_c] != bias_dict_precut[f_c]:\n",
    "                    log_adv_train(f\"bias diff (f,c): {f_c} | precut: {bias_dict_precut[f_c]} | postcut: {bias_dict_postcut[f_c]}\")\n",
    "\n",
    "            \n",
    "            #################### check break criterion ####################\n",
    "            # log_adv_train(\"--------- loop details ---------\")\n",
    "            \n",
    "            if max_itr != -1: # max iteration specified (-1 would mean no max)\n",
    "                if itr_num == max_itr:\n",
    "                    log_adv_train(f\"return from while loop at end of itr_num: {itr_num}\")\n",
    "                    return m, wpos_dict, wneg_dict, bias_dict, cut_dict\n",
    "            \n",
    "            if c_time != 0: # break after timeout if set (0 no timeout)\n",
    "                if time.time() > end_time: # if time now goes past endtime break\n",
    "                    log_adv_train(f\"return from while loop after: {int(time.time() - start_time)}s at end of itr_num: {itr_num}\")\n",
    "                    return m, wpos_dict, wneg_dict, bias_dict, cut_dict\n",
    "            \n",
    "            # otherwise continue loop\n",
    "            continue\n",
    "            \n",
    "        ###############################################################\n",
    "        \n",
    "        else: # no adv example found hence return\n",
    "            log_adv_train(f\"return from while loop at end of itr_num: {itr_num} after achieving ROBUSTNESS\")\n",
    "            print(\"---\\nROBUST ARE WE---\")\n",
    "            robust = True\n",
    "            return m, wpos_dict, wneg_dict, bias_dict, cut_dict # so can use in rest of code for testing/checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST adv_train()\n",
    "testing = 0\n",
    "\n",
    "if testing:\n",
    "\n",
    "    # clear logs\n",
    "    clear_log_adv_example_gen()\n",
    "    clear_log_adv_train()\n",
    "    clear_log_model_optimize()\n",
    "\n",
    "    # Load Data\n",
    "    # dataset = 'wine'\n",
    "    # dataset = 'balance'\n",
    "    dataset = 'zoo'\n",
    "    df, dfx_train, dfx_test, dfy_train, dfy_test = data_load(dataset, print_out=1)\n",
    "\n",
    "    # Adv Train with max_itr > 0 / -1 for no max / 0 for non-adv training\n",
    "    max_itr = 5\n",
    "    adv_idx_ls = [1,3,5]\n",
    "    ibudget = 2\n",
    "    wbudget = 5\n",
    "    count_miss = 0\n",
    "    cb = 0 # not ready yet\n",
    "    score_threshold = 1\n",
    "\n",
    "    global glo_cut_v0\n",
    "    global glo_cut_v1\n",
    "    global glo_cut_v2\n",
    "    global glo_adv_ex_dict\n",
    "\n",
    "    glo_cut_v0 = True\n",
    "    glo_cut_v1 = False\n",
    "    glo_cut_v2 = False\n",
    "    glo_adv_ex_dict = {}\n",
    "\n",
    "    m_time = 5\n",
    "    msub_time = 5\n",
    "    threads = 10\n",
    "    c_time = 0 # max cutting time in secods (0 = no timeout)\n",
    "\n",
    "    m_console = 0\n",
    "    msub_console = 0\n",
    "\n",
    "    alpha = 2\n",
    "    beta = 5\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        ret_adv_train = adv_train(dfx_train, dfy_train, alpha, beta, \n",
    "                                  ibudget, adv_idx_ls, wbudget,\n",
    "                                  m_time, msub_time, threads, max_itr, \n",
    "                                  m_console, msub_console, cb, c_time, count_miss, \n",
    "                                  score_threshold)\n",
    "\n",
    "        (m, wpos_dict, wneg_dict, bias_dict, cut_dict) = ret_adv_train\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('Interupt')\n",
    "    # push(title=f\"d:{dataset} done on {pc_name}\")\n",
    "    train_acc, test_acc = model_info_acc(bias_dict, wpos_dict, wneg_dict, dfx_train, dfy_train, dfx_test, dfy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MAIN #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(record, dataset, n, max_itr, ibudget, adv_idx_ls, wbudget, alpha, beta, beta_dict, \n",
    "         score_threshold, m_time, m_console, c_time, test_size, seed_val):\n",
    "    \n",
    "    global df, dfx_train, dfx_test, dfy_train, dfy_test\n",
    "    \n",
    "    rec_dict = {}\n",
    "    rec_dict['status'] = 'TBD' # put in first then update below\n",
    "    \n",
    "    start_time_main = datetime.now()\n",
    "    start_timer = time.perf_counter()\n",
    "    rec_dict['start_time_main'] = start_time_main.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    \n",
    "    rec_dict['version'] = 1.1\n",
    "    rec_dict['notes'] = ''\n",
    "    rec_dict['pc_name'] = pc_name\n",
    "    \n",
    "    if pc_name == 'Griffon':\n",
    "        rec_dict['threads'] = 6\n",
    "        \n",
    "    if pc_name == 'Henry':\n",
    "        rec_dict['threads'] = 8\n",
    "    \n",
    "    if pc_name == 'Elderax':\n",
    "        rec_dict['threads'] = 10\n",
    "    \n",
    "    if pc_name == 'Queen':\n",
    "        rec_dict['threads'] = 16\n",
    "\n",
    "    # load data\n",
    "    \n",
    "    rec_dict['dataset'] = dataset\n",
    "    # rec_dict['dataset'] = 'post-operative'\n",
    "    # rec_dict['dataset'] = 'zoo'\n",
    "\n",
    "    rec_dict['print_out_data'] = 1\n",
    "    df, dfx_train, dfx_test, dfy_train, dfy_test = data_load(dataset=rec_dict['dataset'], \n",
    "                                                             print_out=rec_dict['print_out_data'],k=0,\n",
    "                                                             test_size=test_size,\n",
    "                                                             n=n,\n",
    "                                                             seed_val=seed_val)\n",
    "    rec_dict['y_classes'] = dfy_train.shape[1]\n",
    "    rec_dict['x_features'] = dfx_train.shape[1]\n",
    "    rec_dict['n-train'] = dfx_train.shape[0]\n",
    "    rec_dict['n-test'] = dfx_test.shape[0]\n",
    "    rec_dict['seed_val'] = seed_val\n",
    "    \n",
    "    # master gurobi\n",
    "    rec_dict['m_time'] = m_time\n",
    "    rec_dict['m_console'] = m_console\n",
    "    \n",
    "    # master hyper\n",
    "    rec_dict['alpha'] = alpha\n",
    "    rec_dict['beta'] = beta\n",
    "    rec_dict['beta_dict'] = beta_dict\n",
    "    rec_dict['score_threshold'] = score_threshold\n",
    "    # rec_dict['alpha'] = 2\n",
    "    # rec_dict['beta'] = 5\n",
    "    # rec_dict['score_threshold'] = 1\n",
    "    \n",
    "    # sub gurobi\n",
    "    rec_dict['msub_time'] = 5\n",
    "    rec_dict['msub_console'] = 0\n",
    "    \n",
    "    # adv Train\n",
    "    rec_dict['c_time'] = c_time # cutting time out | 0: no cutting timeout\n",
    "    rec_dict['count_miss'] = 0 # include mis classify in ibudget / allowance\n",
    "    rec_dict['cb'] = 0 # cb on or off\n",
    "    \n",
    "    rec_dict['max_itr'] = max_itr # 0: no training | -1 for no iteration limit\n",
    "    rec_dict['ibudget'] = ibudget # budget per instance\n",
    "    rec_dict['adv_idx_ls'] = adv_idx_ls\n",
    "    \n",
    "    rec_dict['glo_cut_v0'] = glo_cut_v0\n",
    "    rec_dict['glo_cut_v1'] = glo_cut_v1\n",
    "    rec_dict['glo_cut_v2'] = glo_cut_v2\n",
    "    \n",
    "    rec_dict['wbudget'] = wbudget\n",
    "    # rec_dict['gbudget'] = gbudget # maximum allowable adv examples + misclass per dataset (only less found will cut)\n",
    "    # rec_dict['max_itr'] = 10 # 0: no training | -1 for no iteration limit\n",
    "    # rec_dict['ibudget'] = 2 # budget per instance\n",
    "    # rec_dict['gbudget'] = 5 # maximum allowable adv examples + misclass per dataset (only less found will cut)\n",
    "    \n",
    "    # clear all logs\n",
    "    clear_log_adv_example_gen()\n",
    "    clear_log_adv_train()\n",
    "    clear_log_model_optimize()\n",
    "    clear_log_adv_cut_v2()\n",
    "    clear_log_main()\n",
    "    \n",
    "    ########################### MASTER ONLY #########################\n",
    "    \n",
    "    # build master\n",
    "    ret_mst_model = model_build(dfx=dfx_train, dfy=dfy_train, \n",
    "                                alpha=rec_dict['alpha'], beta=rec_dict['beta'], beta_dict=rec_dict['beta_dict'])    \n",
    "    \n",
    "    (m, epos_dict, eneg_dict, wpos_dict, wneg_dict, wnet_dict, bias_dict, bias_bit_dict) = ret_mst_model \n",
    "    \n",
    "    # optimise master\n",
    "    model_optimize(m, cb=rec_dict['cb'], m_console=rec_dict['m_console'], m_time=rec_dict['m_time'], \n",
    "                   threads=rec_dict['threads'])\n",
    "    \n",
    "    # save/show accuracy\n",
    "    print(\"\\n--- Mst Train ---\")\n",
    "    log_main(\"\\n--- Mst Train ---\")\n",
    "    mst_train_acc, mst_test_acc = model_info_acc(bias_dict=bias_dict, wpos_dict=wpos_dict, wneg_dict=wneg_dict, \n",
    "                                                 dfx_train=dfx_train, dfy_train=dfy_train, \n",
    "                                                 dfx_test=dfx_test, dfy_test=dfy_test)\n",
    "    rec_dict['mst_train_acc'] = mst_train_acc\n",
    "    rec_dict['mst_test_acc'] = mst_test_acc\n",
    "    \n",
    "    # save model\n",
    "    record_folder = create_record_folder(dataset=rec_dict['dataset'], \n",
    "                                         ibudget=rec_dict['ibudget'],\n",
    "                                         start_time_main=start_time_main) # have to use to match times w/folder name\n",
    "    \n",
    "    record_folder_fullpath = os.path.join(os.getcwd(), record_folder)\n",
    "    record_folder_uri = pathlib.Path(record_folder_fullpath).as_uri()\n",
    "    \n",
    "    if record:\n",
    "        m.write(record_folder + \"master.json\")\n",
    "        m.write(record_folder + \"master.lp\")\n",
    "    \n",
    "    # save base details of designated data points (beta_dict)\n",
    "    class_ls = [x for x in dfy_train]\n",
    "    feature_ls = [x for x in dfx_train]\n",
    "    wcomb_dict = model_wcomb(dfx_train, dfy_train, wpos_dict, wneg_dict, cb=False)\n",
    "    \n",
    "    mst_idx_example_ls = {}\n",
    "    mst_idx_example_count = 0\n",
    "    for instance_num1, beta_val in beta_dict.items():\n",
    "        \n",
    "        x_ins = list(dfx_train.loc[instance_num1])\n",
    "        x_ins_label = dfy_train.idxmax(axis=1)[instance_num1]\n",
    "        \n",
    "        # get instance prediction based on current weights/bias\n",
    "        x_ins_pred = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='pred')\n",
    "        x_ins_pred_score = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='score_max')\n",
    "        x_ins_pred_score_dict = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='score_dict')\n",
    "\n",
    "\n",
    "        ############### check if adv example can be generated within budget ###############\n",
    "        \n",
    "        # check for adv example (status = 1 if found, else 0)\n",
    "        ret_adv_example_gen = adv_example_gen(dfx_train, dfy_train, # USE instance\n",
    "                                              wpos_dict, wneg_dict, bias_dict, bias_bit_dict, \n",
    "                                              ibudget=rec_dict['ibudget'], adv_idx_ls=[instance_num1],  # PASS INSTANCE IDX\n",
    "                                              wbudget=rec_dict['wbudget'],\n",
    "                                              msub_console=rec_dict['msub_console'], msub_time=rec_dict['msub_time'], \n",
    "                                              threads=rec_dict['threads'], itr_num=999, \n",
    "                                              count_miss=rec_dict['count_miss'], score_threshold=rec_dict['score_threshold'], \n",
    "                                              cb=False)\n",
    "        (adv_status, adv_count, cut_equ_lhs_ls, nval_rhs_ls) = ret_adv_example_gen\n",
    "        \n",
    "        print(f\"instance_num1: {instance_num1} | label: {x_ins_label} | pred: {x_ins_pred} | correct: {x_ins_label==x_ins_pred} | pred score: {x_ins_pred_score} | gen adv example: {bool(adv_status)} | pred score idx: {x_ins_pred_score_dict}\")\n",
    "        log_main(f\"instance_num1: {instance_num1} | label: {x_ins_label} | pred: {x_ins_pred} | correct: {x_ins_label==x_ins_pred} | pred score: {x_ins_pred_score} | gen adv example: {bool(adv_status)} | pred score idx: {x_ins_pred_score_dict}\")\n",
    "        \n",
    "        if adv_status:\n",
    "                mst_idx_example_ls[instance_num1] = 1 # record example instances\n",
    "                mst_idx_example_count = mst_idx_example_count + 1 # record counts\n",
    "\n",
    "    ########################### ADV TRAIN #########################\n",
    "\n",
    "    # rebuild master (w/o bias index)\n",
    "    \n",
    "    # build master\n",
    "    ret_mst_model = model_build(dfx=dfx_train, dfy=dfy_train, \n",
    "                                alpha=rec_dict['alpha'], beta=rec_dict['beta'], beta_dict=[])    \n",
    "    \n",
    "    (m, epos_dict, eneg_dict, wpos_dict, wneg_dict, wnet_dict, bias_dict, bias_bit_dict) = ret_mst_model \n",
    "    \n",
    "    # optimise master\n",
    "    model_optimize(m, cb=rec_dict['cb'], m_console=rec_dict['m_console'], m_time=rec_dict['m_time'], \n",
    "                   threads=rec_dict['threads'])\n",
    "    \n",
    "    try:\n",
    "        # adv training\n",
    "        ret_adv_model = adv_train(dfx=dfx_train, dfy=dfy_train, \n",
    "                                  alpha=rec_dict['alpha'], beta=rec_dict['beta'], \n",
    "                                  ibudget=rec_dict['ibudget'], adv_idx_ls=rec_dict['adv_idx_ls'], \n",
    "                                  wbudget=rec_dict['wbudget'],\n",
    "                                  m_time=rec_dict['m_time'], msub_time=rec_dict['msub_time'], \n",
    "                                  threads=rec_dict['threads'], max_itr=rec_dict['max_itr'], \n",
    "                                  m_console=rec_dict['m_console'], \n",
    "                                  msub_console=rec_dict['msub_console'], \n",
    "                                  cb=rec_dict['cb'], c_time=rec_dict['c_time'], \n",
    "                                  count_miss=rec_dict['count_miss'], \n",
    "                                  score_threshold=rec_dict['score_threshold'])\n",
    "\n",
    "        (m, wpos_dict, wneg_dict, bias_dict, cut_dict) = ret_adv_model\n",
    "        # rec_dict['cuts'] = len(cut_dict) # causing issues\n",
    "        \n",
    "        # save/show accuracy\n",
    "        print(\"\\n--- Adv Train ---\")\n",
    "        log_main(\"\\n--- Adv Train ---\")\n",
    "        \n",
    "        adv_train_acc, adv_test_acc = model_info_acc(bias_dict=bias_dict, wpos_dict=wpos_dict, wneg_dict=wneg_dict, \n",
    "                                                     dfx_train=dfx_train, dfy_train=dfy_train, \n",
    "                                                     dfx_test=dfx_test, dfy_test=dfy_test)\n",
    "        rec_dict['adv_train_acc'] = adv_train_acc\n",
    "        rec_dict['adv_test_acc'] = adv_test_acc\n",
    "        \n",
    "        rec_dict['status'] = 'completed'\n",
    "        \n",
    "        # save details of designated data points (adv_idx_ls) - but adv_example_gen only sees these\n",
    "        adv_idx_example_ls = {}\n",
    "        adv_idx_example_count = 0\n",
    "        for instance_num1, beta_val in beta_dict.items():\n",
    "            \n",
    "            x_ins = list(dfx_train.loc[instance_num1])\n",
    "            x_ins_label = dfy_train.idxmax(axis=1)[instance_num1]\n",
    "            \n",
    "            # get instance prediction based on current weights/bias\n",
    "            x_ins_pred = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='pred')\n",
    "            x_ins_pred_score = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='score_max')\n",
    "            x_ins_pred_score_dict = model_prediction(wcomb_dict, bias_dict, x_ins, class_ls, cb=False, ret='score_dict')\n",
    "\n",
    "\n",
    "            ############### check if adv example can be generated within budget ###############\n",
    "            \n",
    "            # check for adv example (status = 1 if found, else 0)\n",
    "            ret_adv_example_gen = adv_example_gen(dfx_train, dfy_train, # USE instance\n",
    "                                                wpos_dict, wneg_dict, bias_dict, bias_bit_dict, \n",
    "                                                ibudget=rec_dict['ibudget'], adv_idx_ls=[instance_num1],  # PASS INSTANCE IDX\n",
    "                                                wbudget=rec_dict['wbudget'],\n",
    "                                                msub_console=rec_dict['msub_console'], msub_time=rec_dict['msub_time'], \n",
    "                                                threads=rec_dict['threads'], itr_num=999, \n",
    "                                                count_miss=rec_dict['count_miss'], score_threshold=rec_dict['score_threshold'], \n",
    "                                                cb=False)\n",
    "            (adv_status, adv_count, cut_equ_lhs_ls, nval_rhs_ls) = ret_adv_example_gen\n",
    "            \n",
    "            print(f\"instance_num1: {instance_num1} | label: {x_ins_label} | pred: {x_ins_pred} | correct: {x_ins_label==x_ins_pred} | pred score: {x_ins_pred_score} | gen adv example: {bool(adv_status)} | pred score idx: {x_ins_pred_score_dict}\")\n",
    "            log_main(f\"instance_num1: {instance_num1} | label: {x_ins_label} | pred: {x_ins_pred} | correct: {x_ins_label==x_ins_pred} | pred score: {x_ins_pred_score} | gen adv example: {bool(adv_status)} | pred score idx: {x_ins_pred_score_dict}\")\n",
    "\n",
    "            if adv_status:\n",
    "                adv_idx_example_ls[instance_num1] = 1 # record example instances\n",
    "                adv_idx_example_count = adv_idx_example_count + 1 # record counts\n",
    "        \n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('interrupted')\n",
    "        log_main('interrupted')\n",
    "        rec_dict['status'] = 'interrupted'\n",
    "    \n",
    "    # record total for output\n",
    "    rec_dict['mst_idx_example_ls'] = mst_idx_example_ls\n",
    "    rec_dict['mst_idx_example_count'] = mst_idx_example_count\n",
    "    \n",
    "    rec_dict['adv_idx_example_ls'] = adv_idx_example_ls\n",
    "    rec_dict['adv_idx_example_count'] = adv_idx_example_count\n",
    "    \n",
    "    print(f\"mst examples:{mst_idx_example_count} | adv examples:{adv_idx_example_count} | diff:{mst_idx_example_count-adv_idx_example_count}\")\n",
    "    \n",
    "    # end timer\n",
    "    end_timer = time.perf_counter()\n",
    "    rec_dict['time_s'] = f\"{end_timer - start_timer:0.0f}\"\n",
    "    \n",
    "    # save\n",
    "    if record:\n",
    "        # save model\n",
    "        m.write(record_folder + \"adv.json\")\n",
    "        m.write(record_folder + \"adv.lp\")\n",
    "        rec_dict['record_folder_uri'] = record_folder_uri # add at end\n",
    "        \n",
    "        # save logs and experiments\n",
    "        # shutil.copy2(log_folder + \"adv_example_gen.log\", record_folder + \"adv_example_gen.log\")\n",
    "        # shutil.copy2(log_folder + \"adv_train.log\", record_folder + \"adv_train.log\")\n",
    "        # shutil.copy2(log_folder + \"model_optimize.log\", record_folder + \"model_optimize.log\")\n",
    "        \n",
    "        # copy and save all logs\n",
    "        files=os.listdir(log_folder)\n",
    "        for fname in files:\n",
    "            shutil.copy2(os.path.join(log_folder,fname), record_folder)\n",
    "        \n",
    "        # add record to experiements.csv\n",
    "        if os.path.isfile(f\"records/experiments-{pc_name}.csv\"): # append if exists\n",
    "            with open(f\"records/experiments-{pc_name}.csv\", 'a', newline='') as f:\n",
    "                w = csv.DictWriter(f, rec_dict.keys())\n",
    "                w.writerow(rec_dict)\n",
    "        else: # otherwise make new \n",
    "            with open(f\"records/experiments-{pc_name}.csv\", 'w', newline='') as f:\n",
    "                w = csv.DictWriter(f, rec_dict.keys())\n",
    "                w.writeheader()\n",
    "                w.writerow(rec_dict)\n",
    "\n",
    "    # active on Griffon & Henry by default\n",
    "    pushover_msg = f\"\"\"\n",
    "    ibudget: {rec_dict['ibudget']}\n",
    "    adv_idx_ls: {rec_dict['adv_idx_ls']}\n",
    "    \n",
    "    mst_train_acc: {rec_dict['mst_train_acc']}\n",
    "    mst_test_acc: {rec_dict['mst_test_acc']}\n",
    "    \n",
    "    adv_train_acc: {rec_dict['adv_train_acc']}\n",
    "    adv_test_acc: {rec_dict['adv_test_acc']}\n",
    "    \n",
    "    time_s: {rec_dict['time_s']}\n",
    "    \"\"\"\n",
    "    pushover(title=f\"{dataset} | {pc_name} | {rec_dict['ibudget']}\", \n",
    "             msg=pushover_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: zoo             | y_classes: 7     | x_features: 21    | n-train: 70    | n-test: 31   \n",
      "dataset: student         | y_classes: 8     | x_features: 110   | n-train: 101   | n-test: 44   \n",
      "dataset: phishing        | y_classes: 3     | x_features: 23    | n-train: 947   | n-test: 406  \n",
      "dataset: heart           | y_classes: 5     | x_features: 132   | n-train: 212   | n-test: 91   \n",
      "dataset: wine            | y_classes: 3     | x_features: 150   | n-train: 124   | n-test: 54   \n",
      "dataset: glass           | y_classes: 6     | x_features: 237   | n-train: 149   | n-test: 65   \n",
      "dataset: nist            | y_classes: 10    | x_features: 239   | n-train: 2676  | n-test: 1147 \n",
      "dataset: post-operative  | y_classes: 3     | x_features: 22    | n-train: 63    | n-test: 27   \n",
      "dataset: flag            | y_classes: 10    | x_features: 287   | n-train: 135   | n-test: 59   \n",
      "dataset: balance         | y_classes: 3     | x_features: 20    | n-train: 437   | n-test: 188  \n",
      "dataset: hayes-roth      | y_classes: 4     | x_features: 16    | n-train: 112   | n-test: 48   \n",
      "dataset: lymphography    | y_classes: 4     | x_features: 50    | n-train: 103   | n-test: 45   \n",
      "dataset: dermatology     | y_classes: 6     | x_features: 189   | n-train: 256   | n-test: 110  \n",
      "dataset: lenses          | y_classes: 3     | x_features: 6     | n-train: 16    | n-test: 8    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 6, 16, 8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test split w/test_size: 0.5\n",
      "y_classes: 3 | x_features: 22 | n-train: 45 | n-test: 45\n",
      "loaded: post-operative\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-08-06\n",
      "\n",
      "--- Mst Train ---\n",
      "Train Acc: 68.89 | Test Acc: 66.67 | Diff: -2.22\n",
      "instance_num1: 0 | label: 0 | pred: 0 | correct: True | pred score: 24.0 | gen adv example: False | pred score idx: {0: 24.0, 1: 13.0, 2: 16.0}\n",
      "instance_num1: 1 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 15.0, 2: 15.0}\n",
      "instance_num1: 2 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 14.0, 2: 15.0}\n",
      "instance_num1: 3 | label: 2 | pred: 0 | correct: False | pred score: 20.0 | gen adv example: False | pred score idx: {0: 20.0, 1: 14.0, 2: 20.0}\n",
      "instance_num1: 4 | label: 2 | pred: 0 | correct: False | pred score: 20.0 | gen adv example: False | pred score idx: {0: 20.0, 1: 17.0, 2: 20.0}\n",
      "instance_num1: 5 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 13.0, 2: 15.0}\n",
      "instance_num1: 6 | label: 0 | pred: 0 | correct: True | pred score: 26.0 | gen adv example: False | pred score idx: {0: 26.0, 1: 14.0, 2: 14.0}\n",
      "instance_num1: 7 | label: 0 | pred: 0 | correct: True | pred score: 23.0 | gen adv example: False | pred score idx: {0: 23.0, 1: 15.0, 2: 17.0}\n",
      "instance_num1: 8 | label: 0 | pred: 0 | correct: True | pred score: 26.0 | gen adv example: False | pred score idx: {0: 26.0, 1: 14.0, 2: 14.0}\n",
      "instance_num1: 9 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 13.0, 2: 13.0}\n",
      "---\n",
      "ROBUST ARE WE---\n",
      "\n",
      "--- Adv Train ---\n",
      "Train Acc: 71.11 | Test Acc: 71.11 | Diff: 0.0\n",
      "instance_num1: 0 | label: 0 | pred: 0 | correct: True | pred score: 24.0 | gen adv example: False | pred score idx: {0: 24.0, 1: 0.0, 2: 3.0}\n",
      "instance_num1: 1 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 2.0, 2: 2.0}\n",
      "instance_num1: 2 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 1.0, 2: 2.0}\n",
      "instance_num1: 3 | label: 2 | pred: 0 | correct: False | pred score: 20.0 | gen adv example: False | pred score idx: {0: 20.0, 1: 1.0, 2: 7.0}\n",
      "instance_num1: 4 | label: 2 | pred: 0 | correct: False | pred score: 20.0 | gen adv example: False | pred score idx: {0: 20.0, 1: 4.0, 2: 7.0}\n",
      "instance_num1: 5 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 0.0, 2: 2.0}\n",
      "instance_num1: 6 | label: 0 | pred: 0 | correct: True | pred score: 26.0 | gen adv example: False | pred score idx: {0: 26.0, 1: 1.0, 2: 1.0}\n",
      "instance_num1: 7 | label: 0 | pred: 0 | correct: True | pred score: 23.0 | gen adv example: False | pred score idx: {0: 23.0, 1: 2.0, 2: 4.0}\n",
      "instance_num1: 8 | label: 0 | pred: 0 | correct: True | pred score: 26.0 | gen adv example: False | pred score idx: {0: 26.0, 1: 1.0, 2: 1.0}\n",
      "instance_num1: 9 | label: 0 | pred: 0 | correct: True | pred score: 25.0 | gen adv example: False | pred score idx: {0: 25.0, 1: 0.0, 2: 0.0}\n",
      "mst examples:0 | adv examples:0 | diff:0\n",
      "count of adv example: {}\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "onedrive('stop') # active on Griffon & Henry by default\n",
    "\n",
    "######### SELECT PROTECTED DATA POINTS ##########\n",
    "beta_idx = range(10)\n",
    "beta_val = [50] * len(beta_idx)\n",
    "beta_dict = dict(zip(beta_idx, beta_val))  #=> {'a': 1, 'b': 2\n",
    "adv_idx_ls = [instance_num for instance_num in beta_dict]\n",
    "\n",
    "dataset = 'post-operative'\n",
    "# dataset = 'balance'\n",
    "# dataset = 'phishing'\n",
    "\n",
    "global glo_adv_ex_dict\n",
    "global glo_PoolSolutionsN\n",
    "global glo_cut_v0\n",
    "global glo_cut_v1\n",
    "global glo_cut_v2\n",
    "\n",
    "glo_adv_ex_dict = {} # initialise\n",
    "glo_cut_v0 = True\n",
    "glo_cut_v1 = False\n",
    "glo_cut_v2 = False\n",
    "glo_PoolSolutionsN = 10\n",
    "\n",
    "# seed_val = 1 \n",
    "# seed_val = 12 \n",
    "# seed_val = 123\n",
    "seed_val = 1234\n",
    "# seed_val = 12345\n",
    "# seed_val = 123456\n",
    "# seed_val = 1234567\n",
    "# seed_val = 12345678\n",
    "# seed_val = 123456789\n",
    "\n",
    "main(record=0,\n",
    "     dataset=dataset, \n",
    "     n=0,\n",
    "     max_itr=1000, \n",
    "     ibudget=2, \n",
    "     adv_idx_ls=adv_idx_ls,\n",
    "     wbudget=5, \n",
    "     alpha=5, \n",
    "     beta=10,\n",
    "     beta_dict=beta_dict,\n",
    "     score_threshold=1,\n",
    "     m_time=30,\n",
    "     m_console=0,\n",
    "     c_time=0,\n",
    "     test_size=0.5,\n",
    "     seed_val=seed_val)\n",
    "\n",
    "onedrive('start')\n",
    "\n",
    "print(f\"count of adv example: {glo_adv_ex_dict}\")\n",
    "log_main(f\"instance/count of adv examples: {glo_adv_ex_dict}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('22_MT_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c3daec2025be5ef64d27a31c51c28d271774306112d53d44c3e6cdb6dc5a3c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
